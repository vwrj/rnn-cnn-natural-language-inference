{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "import io\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import pdb\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    print(n, d)\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        if i == VOCAB_SIZE:\n",
    "            break\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "        i += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "VOCAB_SIZE = 50000\n",
    "\n",
    "def build_vocab():\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    word_vectors = pkl.load(open(\"fasttext_word_vectors.p\", \"rb\"))\n",
    "    id2token = list(word_vectors.keys())\n",
    "    token2id = dict(zip(word_vectors, range(2,2+len(word_vectors)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return word_vectors, token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors, token2id, id2token = build_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50002, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_weights = np.array(list(word_vectors.values()))\n",
    "pad_vec = np.zeros((1, 300))\n",
    "unk_vec = np.random.randn(1, 300) * 0.01\n",
    "pad_unk_vecs = np.vstack((pad_vec, unk_vec))\n",
    "_WEIGHTS = np.vstack((pad_unk_vecs, _weights))\n",
    "_WEIGHTS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating toy dataset with 5000 training data, 1000 validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snli_train = pd.read_csv('/Users/vrajiv/Desktop/rnn-cnn-natural-language-inference/hw2_data/snli_train.tsv', sep='\\t')\n",
    "snli_train = pd.read_csv('snli_train.tsv', sep='\\t')\n",
    "TRAIN_VAL_SPLIT = 99000\n",
    "DATA_SIZE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "sent1_data = list(snli_train[\"sentence1\"])[:DATA_SIZE]\n",
    "sent2_data = list(snli_train[\"sentence2\"])[:DATA_SIZE]\n",
    "data_label = list(snli_train[\"label\"])[:DATA_SIZE]\n",
    "print(len(sent1_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_val = pd.read_csv('snli_val.tsv', sep='\\t')\n",
    "sent1_val_data = list(snli_val[\"sentence1\"])\n",
    "sent2_val_data = list(snli_val[\"sentence2\"])\n",
    "val_label_data = list(snli_val[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_to_integers(data_label):\n",
    "    for i in range(len(data_label)):\n",
    "        if data_label[i] == \"contradiction\":\n",
    "            data_label[i] = 0\n",
    "        elif data_label[i] == \"entailment\":\n",
    "            data_label[i] = 1\n",
    "        elif data_label[i] == \"neutral\":\n",
    "            data_label[i] = 2\n",
    "    return data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = convert_labels_to_integers(data_label)\n",
    "val_label_data = convert_labels_to_integers(val_label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "random.Random(SEED).shuffle(sent1_data)\n",
    "random.Random(SEED).shuffle(sent2_data)\n",
    "random.Random(SEED).shuffle(data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A guy taking a photo of another guy who is standing in front of a broken television .\n",
      "A woman is playing a video game .\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def verify_order(sent1_data, sent2_data, data_label):\n",
    "    i = random.randint(1, len(sent1_data))\n",
    "    print(sent1_data[i])\n",
    "    print(sent2_data[i])\n",
    "    print(data_label[i])\n",
    "\n",
    "verify_order(sent1_data, sent2_data, data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A busy street scene on a rainy day full of umbrella toting walkers .\n",
      "A bunch of people holding umbrellas on a rainy day .\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "verify_order(sent1_val_data, sent2_val_data, val_label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1_train = sent1_data[:TRAIN_VAL_SPLIT]\n",
    "sent2_train = sent2_data[:TRAIN_VAL_SPLIT]\n",
    "train_label = data_label[:TRAIN_VAL_SPLIT]\n",
    "\n",
    "sent1_val = sent1_val_data\n",
    "sent2_val = sent2_val_data\n",
    "val_label = val_label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99000 99000 99000\n",
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(sent1_train), len(sent2_train), len(train_label))\n",
    "print(len(sent1_val), len(sent2_val), len(val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man is walking down a pavement path .\n",
      "the man is in the shower\n",
      "0\n",
      "A woman stands at a podium with a slide show behind her .\n",
      "A woman is standing at a podium .\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "verify_order(sent1_train, sent2_train, train_label)\n",
    "verify_order(sent1_val, sent2_val, val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence_list):\n",
    "    return [word_tokenize(sentence_list[i]) for i in range(len(sentence_list))]\n",
    "\n",
    "# train\n",
    "sent1_train_tokenized = tokenize(sent1_train)\n",
    "sent2_train_tokenized = tokenize(sent2_train)\n",
    "\n",
    "# val\n",
    "sent1_val_tokenized = tokenize(sent1_val)\n",
    "sent2_val_tokenized = tokenize(sent2_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"One-hot encoding\"\n",
    "#### Represent each sentence as a vector of indices in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "sent1_train_indices = token2index_dataset(sent1_train_tokenized)\n",
    "sent2_train_indices = token2index_dataset(sent2_train_tokenized)\n",
    "\n",
    "# val\n",
    "sent1_val_indices = token2index_dataset(sent1_val_tokenized)\n",
    "sent2_val_indices = token2index_dataset(sent2_val_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 30\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TwoSentencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sent1_data_list, sent2_data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param sent1_data_list: list of sentence1's (index matches sentence2's and target_list below)\n",
    "        @param sent2_data_list: list of sentence2's\n",
    "        @param target_list: list of correct labels\n",
    "\n",
    "        \"\"\"\n",
    "        self.sent1_data_list = sent1_data_list\n",
    "        self.sent2_data_list = sent2_data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.sent1_data_list) == len(self.target_list) and len(self.sent2_data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent1_data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        ###\n",
    "        ### Returns [[sentence, 1, tokens], [sentence, 2, tokens]]\n",
    "        ###\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        sent1_tokens_idx = self.sent1_data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        sent2_tokens_idx = self.sent2_data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        combined_tokens_idx = [sent1_tokens_idx, sent2_tokens_idx]\n",
    "        label = self.target_list[key]\n",
    "        return [combined_tokens_idx, len(sent1_tokens_idx), len(sent2_tokens_idx), label]\n",
    "\n",
    "def twosentences_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    sent1_data_list = []\n",
    "    sent2_data_list = []\n",
    "    sent1_length_list = []\n",
    "    sent2_length_list = []\n",
    "    label_list = []\n",
    "    combined_data_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[3])\n",
    "        sent1_length_list.append(datum[1])\n",
    "        sent2_length_list.append(datum[2])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_1 = np.pad(np.array(datum[0][0]), pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_2 = np.pad(np.array(datum[0][1]), pad_width=((0,MAX_SENTENCE_LENGTH-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        combined_data_list.append([padded_vec_1, padded_vec_2])\n",
    "    return [torch.from_numpy(np.array(combined_data_list)), \n",
    "            torch.LongTensor(sent1_length_list), torch.LongTensor(sent2_length_list), torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TwoSentencesDataset(sent1_train_indices, sent2_train_indices, train_label)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           collate_fn=twosentences_collate_func,\n",
    "                                           #shuffle=True\n",
    "                                          )\n",
    "\n",
    "val_dataset = TwoSentencesDataset(sent1_val_indices, sent2_val_indices, val_label)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           collate_fn=twosentences_collate_func,\n",
    "                                           #shuffle=True\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(_WEIGHTS))\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.maxpool = nn.MaxPool1d(30)\n",
    "        self.linear1 = nn.Linear(2*hidden_size, 100)\n",
    "        self.linear2 = nn.Linear(100, num_classes)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x, sent1_lengths, sent2_lengths):\n",
    "        \n",
    "        batch_size = x.size()[0]\n",
    "        seq_len = x.size()[2]\n",
    "        \n",
    "        sent1s = torch.tensor(x[:, 0, :]).cuda()\n",
    "        sent2s = torch.tensor(x[:, 1, :]).cuda()\n",
    "        ordered_sents = torch.cat([sent1s, sent2s], dim=0).cuda()\n",
    "\n",
    "        embed = self.embedding(ordered_sents)\n",
    "        hidden = self.conv1(embed.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(2*batch_size, seq_len, hidden.size(-1))\n",
    "\n",
    "        hidden = self.conv2(hidden.transpose(1,2)).transpose(1,2)\n",
    "        hidden = F.relu(hidden.contiguous().view(-1, hidden.size(-1))).view(2*batch_size, seq_len, hidden.size(-1))\n",
    "        hidden = self.maxpool(hidden.transpose(1, 2)).transpose(1, 2).squeeze(dim=1)\n",
    "        \n",
    "        hidden_sent1s = hidden[0:batch_size, :]\n",
    "        hidden_sent2s = hidden[batch_size:, :]     \n",
    "        \n",
    "        linear1 = self.linear1(torch.cat([hidden_sent1s, hidden_sent2s], dim=1))\n",
    "        logits = self.linear2(linear1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Helper function that tests the model's performance on a dataset\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for (data, sent1_lengths, sent2_lengths, labels) in loader:\n",
    "        data_batch, sent1_length_batch, sent2_length_batch, label_batch = data.cuda(), sent1_lengths.cuda(), sent2_lengths.cuda(), labels.cuda()\n",
    "        outputs = F.softmax(model(data_batch, sent1_length_batch, sent2_length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        labels = labels.cuda()\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "def train_model(model, lr = 0.001, num_epochs = 7, criterion = nn.CrossEntropyLoss()):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, sent1_lengths, sent2_lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, sent1_length_batch, sent2_length_batch, label_batch = data.cuda(), sent1_lengths.cuda(), sent2_lengths.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, sent1_length_batch, sent2_length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 100 iterations\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Training Loss: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/7], Step: [101/3094], Validation Acc: 43.7\n",
      "Epoch: [1/7], Step: [101/3094], Training Loss: 1.046177625656128\n",
      "Epoch: [1/7], Step: [201/3094], Validation Acc: 49.4\n",
      "Epoch: [1/7], Step: [201/3094], Training Loss: 0.9624378085136414\n",
      "Epoch: [1/7], Step: [301/3094], Validation Acc: 48.8\n",
      "Epoch: [1/7], Step: [301/3094], Training Loss: 0.9790204763412476\n",
      "Epoch: [1/7], Step: [401/3094], Validation Acc: 51.7\n",
      "Epoch: [1/7], Step: [401/3094], Training Loss: 0.9888293743133545\n",
      "Epoch: [1/7], Step: [501/3094], Validation Acc: 52.4\n",
      "Epoch: [1/7], Step: [501/3094], Training Loss: 0.7824007272720337\n",
      "Epoch: [1/7], Step: [601/3094], Validation Acc: 57.4\n",
      "Epoch: [1/7], Step: [601/3094], Training Loss: 1.1802796125411987\n",
      "Epoch: [1/7], Step: [701/3094], Validation Acc: 57.8\n",
      "Epoch: [1/7], Step: [701/3094], Training Loss: 0.8083867430686951\n",
      "Epoch: [1/7], Step: [801/3094], Validation Acc: 56.7\n",
      "Epoch: [1/7], Step: [801/3094], Training Loss: 0.7674963474273682\n",
      "Epoch: [1/7], Step: [901/3094], Validation Acc: 58.5\n",
      "Epoch: [1/7], Step: [901/3094], Training Loss: 0.8663236498832703\n",
      "Epoch: [1/7], Step: [1001/3094], Validation Acc: 60.1\n",
      "Epoch: [1/7], Step: [1001/3094], Training Loss: 0.9164101481437683\n",
      "Epoch: [1/7], Step: [1101/3094], Validation Acc: 59.5\n",
      "Epoch: [1/7], Step: [1101/3094], Training Loss: 0.7570244669914246\n",
      "Epoch: [1/7], Step: [1201/3094], Validation Acc: 57.1\n",
      "Epoch: [1/7], Step: [1201/3094], Training Loss: 0.7785417437553406\n",
      "Epoch: [1/7], Step: [1301/3094], Validation Acc: 57.9\n",
      "Epoch: [1/7], Step: [1301/3094], Training Loss: 1.0970045328140259\n",
      "Epoch: [1/7], Step: [1401/3094], Validation Acc: 60.2\n",
      "Epoch: [1/7], Step: [1401/3094], Training Loss: 1.023443579673767\n",
      "Epoch: [1/7], Step: [1501/3094], Validation Acc: 59.0\n",
      "Epoch: [1/7], Step: [1501/3094], Training Loss: 0.8546221256256104\n",
      "Epoch: [1/7], Step: [1601/3094], Validation Acc: 58.7\n",
      "Epoch: [1/7], Step: [1601/3094], Training Loss: 0.8196437954902649\n",
      "Epoch: [1/7], Step: [1701/3094], Validation Acc: 59.1\n",
      "Epoch: [1/7], Step: [1701/3094], Training Loss: 0.9151164889335632\n",
      "Epoch: [1/7], Step: [1801/3094], Validation Acc: 62.1\n",
      "Epoch: [1/7], Step: [1801/3094], Training Loss: 1.0017156600952148\n",
      "Epoch: [1/7], Step: [1901/3094], Validation Acc: 59.1\n",
      "Epoch: [1/7], Step: [1901/3094], Training Loss: 0.8284381031990051\n",
      "Epoch: [1/7], Step: [2001/3094], Validation Acc: 61.1\n",
      "Epoch: [1/7], Step: [2001/3094], Training Loss: 0.6958564519882202\n",
      "Epoch: [1/7], Step: [2101/3094], Validation Acc: 60.2\n",
      "Epoch: [1/7], Step: [2101/3094], Training Loss: 0.8875651955604553\n",
      "Epoch: [1/7], Step: [2201/3094], Validation Acc: 60.6\n",
      "Epoch: [1/7], Step: [2201/3094], Training Loss: 0.7228743433952332\n",
      "Epoch: [1/7], Step: [2301/3094], Validation Acc: 59.8\n",
      "Epoch: [1/7], Step: [2301/3094], Training Loss: 0.6232510209083557\n",
      "Epoch: [1/7], Step: [2401/3094], Validation Acc: 62.0\n",
      "Epoch: [1/7], Step: [2401/3094], Training Loss: 0.8789061903953552\n",
      "Epoch: [1/7], Step: [2501/3094], Validation Acc: 60.9\n",
      "Epoch: [1/7], Step: [2501/3094], Training Loss: 1.0869687795639038\n",
      "Epoch: [1/7], Step: [2601/3094], Validation Acc: 61.5\n",
      "Epoch: [1/7], Step: [2601/3094], Training Loss: 0.8686781525611877\n",
      "Epoch: [1/7], Step: [2701/3094], Validation Acc: 62.5\n",
      "Epoch: [1/7], Step: [2701/3094], Training Loss: 0.8864362835884094\n",
      "Epoch: [1/7], Step: [2801/3094], Validation Acc: 61.7\n",
      "Epoch: [1/7], Step: [2801/3094], Training Loss: 1.1449120044708252\n",
      "Epoch: [1/7], Step: [2901/3094], Validation Acc: 61.9\n",
      "Epoch: [1/7], Step: [2901/3094], Training Loss: 0.8380619883537292\n",
      "Epoch: [1/7], Step: [3001/3094], Validation Acc: 61.5\n",
      "Epoch: [1/7], Step: [3001/3094], Training Loss: 0.8902712464332581\n",
      "Epoch: [2/7], Step: [101/3094], Validation Acc: 61.4\n",
      "Epoch: [2/7], Step: [101/3094], Training Loss: 0.7948148250579834\n",
      "Epoch: [2/7], Step: [201/3094], Validation Acc: 61.3\n",
      "Epoch: [2/7], Step: [201/3094], Training Loss: 0.9333180785179138\n",
      "Epoch: [2/7], Step: [301/3094], Validation Acc: 62.1\n",
      "Epoch: [2/7], Step: [301/3094], Training Loss: 0.8605767488479614\n",
      "Epoch: [2/7], Step: [401/3094], Validation Acc: 62.2\n",
      "Epoch: [2/7], Step: [401/3094], Training Loss: 0.8408777117729187\n",
      "Epoch: [2/7], Step: [501/3094], Validation Acc: 60.7\n",
      "Epoch: [2/7], Step: [501/3094], Training Loss: 0.614317774772644\n",
      "Epoch: [2/7], Step: [601/3094], Validation Acc: 61.8\n",
      "Epoch: [2/7], Step: [601/3094], Training Loss: 1.113818645477295\n",
      "Epoch: [2/7], Step: [701/3094], Validation Acc: 62.2\n",
      "Epoch: [2/7], Step: [701/3094], Training Loss: 0.6778696775436401\n",
      "Epoch: [2/7], Step: [801/3094], Validation Acc: 59.4\n",
      "Epoch: [2/7], Step: [801/3094], Training Loss: 0.6968370079994202\n",
      "Epoch: [2/7], Step: [901/3094], Validation Acc: 62.1\n",
      "Epoch: [2/7], Step: [901/3094], Training Loss: 0.7297902703285217\n",
      "Epoch: [2/7], Step: [1001/3094], Validation Acc: 61.8\n",
      "Epoch: [2/7], Step: [1001/3094], Training Loss: 0.7669020891189575\n",
      "Epoch: [2/7], Step: [1101/3094], Validation Acc: 62.3\n",
      "Epoch: [2/7], Step: [1101/3094], Training Loss: 0.7920268774032593\n",
      "Epoch: [2/7], Step: [1201/3094], Validation Acc: 61.7\n",
      "Epoch: [2/7], Step: [1201/3094], Training Loss: 0.7180790901184082\n",
      "Epoch: [2/7], Step: [1301/3094], Validation Acc: 60.9\n",
      "Epoch: [2/7], Step: [1301/3094], Training Loss: 1.0492527484893799\n",
      "Epoch: [2/7], Step: [1401/3094], Validation Acc: 61.2\n",
      "Epoch: [2/7], Step: [1401/3094], Training Loss: 0.9339379668235779\n",
      "Epoch: [2/7], Step: [1501/3094], Validation Acc: 61.4\n",
      "Epoch: [2/7], Step: [1501/3094], Training Loss: 0.7827607989311218\n",
      "Epoch: [2/7], Step: [1601/3094], Validation Acc: 60.3\n",
      "Epoch: [2/7], Step: [1601/3094], Training Loss: 0.8034064173698425\n",
      "Epoch: [2/7], Step: [1701/3094], Validation Acc: 59.6\n",
      "Epoch: [2/7], Step: [1701/3094], Training Loss: 0.8648808002471924\n",
      "Epoch: [2/7], Step: [1801/3094], Validation Acc: 62.2\n",
      "Epoch: [2/7], Step: [1801/3094], Training Loss: 0.9391523599624634\n",
      "Epoch: [2/7], Step: [1901/3094], Validation Acc: 61.6\n",
      "Epoch: [2/7], Step: [1901/3094], Training Loss: 0.807898223400116\n",
      "Epoch: [2/7], Step: [2001/3094], Validation Acc: 62.6\n",
      "Epoch: [2/7], Step: [2001/3094], Training Loss: 0.6650230884552002\n",
      "Epoch: [2/7], Step: [2101/3094], Validation Acc: 62.2\n",
      "Epoch: [2/7], Step: [2101/3094], Training Loss: 0.8630189299583435\n",
      "Epoch: [2/7], Step: [2201/3094], Validation Acc: 62.7\n",
      "Epoch: [2/7], Step: [2201/3094], Training Loss: 0.6780197024345398\n",
      "Epoch: [2/7], Step: [2301/3094], Validation Acc: 62.2\n",
      "Epoch: [2/7], Step: [2301/3094], Training Loss: 0.5850768089294434\n",
      "Epoch: [2/7], Step: [2401/3094], Validation Acc: 62.5\n",
      "Epoch: [2/7], Step: [2401/3094], Training Loss: 0.8502566814422607\n",
      "Epoch: [2/7], Step: [2501/3094], Validation Acc: 61.8\n",
      "Epoch: [2/7], Step: [2501/3094], Training Loss: 1.0289868116378784\n",
      "Epoch: [2/7], Step: [2601/3094], Validation Acc: 63.1\n",
      "Epoch: [2/7], Step: [2601/3094], Training Loss: 0.823670506477356\n",
      "Epoch: [2/7], Step: [2701/3094], Validation Acc: 63.0\n",
      "Epoch: [2/7], Step: [2701/3094], Training Loss: 0.8550412058830261\n",
      "Epoch: [2/7], Step: [2801/3094], Validation Acc: 62.2\n",
      "Epoch: [2/7], Step: [2801/3094], Training Loss: 1.094630479812622\n",
      "Epoch: [2/7], Step: [2901/3094], Validation Acc: 62.2\n",
      "Epoch: [2/7], Step: [2901/3094], Training Loss: 0.8322635889053345\n",
      "Epoch: [2/7], Step: [3001/3094], Validation Acc: 62.8\n",
      "Epoch: [2/7], Step: [3001/3094], Training Loss: 0.8550923466682434\n",
      "Epoch: [3/7], Step: [101/3094], Validation Acc: 62.6\n",
      "Epoch: [3/7], Step: [101/3094], Training Loss: 0.7435791492462158\n",
      "Epoch: [3/7], Step: [201/3094], Validation Acc: 63.0\n",
      "Epoch: [3/7], Step: [201/3094], Training Loss: 0.9233427047729492\n",
      "Epoch: [3/7], Step: [301/3094], Validation Acc: 62.3\n",
      "Epoch: [3/7], Step: [301/3094], Training Loss: 0.8139219880104065\n",
      "Epoch: [3/7], Step: [401/3094], Validation Acc: 62.6\n",
      "Epoch: [3/7], Step: [401/3094], Training Loss: 0.809466540813446\n",
      "Epoch: [3/7], Step: [501/3094], Validation Acc: 62.0\n",
      "Epoch: [3/7], Step: [501/3094], Training Loss: 0.5396395325660706\n",
      "Epoch: [3/7], Step: [601/3094], Validation Acc: 61.7\n",
      "Epoch: [3/7], Step: [601/3094], Training Loss: 1.0955734252929688\n",
      "Epoch: [3/7], Step: [701/3094], Validation Acc: 62.7\n",
      "Epoch: [3/7], Step: [701/3094], Training Loss: 0.6255992650985718\n",
      "Epoch: [3/7], Step: [801/3094], Validation Acc: 61.9\n",
      "Epoch: [3/7], Step: [801/3094], Training Loss: 0.6752409934997559\n",
      "Epoch: [3/7], Step: [901/3094], Validation Acc: 62.7\n",
      "Epoch: [3/7], Step: [901/3094], Training Loss: 0.6537364721298218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/7], Step: [1001/3094], Validation Acc: 62.4\n",
      "Epoch: [3/7], Step: [1001/3094], Training Loss: 0.744685173034668\n",
      "Epoch: [3/7], Step: [1101/3094], Validation Acc: 62.8\n",
      "Epoch: [3/7], Step: [1101/3094], Training Loss: 0.7696452140808105\n",
      "Epoch: [3/7], Step: [1201/3094], Validation Acc: 63.1\n",
      "Epoch: [3/7], Step: [1201/3094], Training Loss: 0.6902296543121338\n",
      "Epoch: [3/7], Step: [1301/3094], Validation Acc: 61.9\n",
      "Epoch: [3/7], Step: [1301/3094], Training Loss: 0.9985197186470032\n",
      "Epoch: [3/7], Step: [1401/3094], Validation Acc: 61.9\n",
      "Epoch: [3/7], Step: [1401/3094], Training Loss: 0.9367342591285706\n",
      "Epoch: [3/7], Step: [1501/3094], Validation Acc: 62.4\n",
      "Epoch: [3/7], Step: [1501/3094], Training Loss: 0.7623982429504395\n",
      "Epoch: [3/7], Step: [1601/3094], Validation Acc: 61.6\n",
      "Epoch: [3/7], Step: [1601/3094], Training Loss: 0.7721515893936157\n",
      "Epoch: [3/7], Step: [1701/3094], Validation Acc: 62.2\n",
      "Epoch: [3/7], Step: [1701/3094], Training Loss: 0.8199191689491272\n",
      "Epoch: [3/7], Step: [1801/3094], Validation Acc: 62.7\n",
      "Epoch: [3/7], Step: [1801/3094], Training Loss: 0.8701429963111877\n",
      "Epoch: [3/7], Step: [1901/3094], Validation Acc: 63.1\n",
      "Epoch: [3/7], Step: [1901/3094], Training Loss: 0.7633912563323975\n",
      "Epoch: [3/7], Step: [2001/3094], Validation Acc: 64.2\n",
      "Epoch: [3/7], Step: [2001/3094], Training Loss: 0.5697407126426697\n",
      "Epoch: [3/7], Step: [2101/3094], Validation Acc: 64.3\n",
      "Epoch: [3/7], Step: [2101/3094], Training Loss: 0.8354921340942383\n",
      "Epoch: [3/7], Step: [2201/3094], Validation Acc: 63.1\n",
      "Epoch: [3/7], Step: [2201/3094], Training Loss: 0.6475633382797241\n",
      "Epoch: [3/7], Step: [2301/3094], Validation Acc: 62.8\n",
      "Epoch: [3/7], Step: [2301/3094], Training Loss: 0.5722549557685852\n",
      "Epoch: [3/7], Step: [2401/3094], Validation Acc: 64.2\n",
      "Epoch: [3/7], Step: [2401/3094], Training Loss: 0.7999284267425537\n",
      "Epoch: [3/7], Step: [2501/3094], Validation Acc: 62.5\n",
      "Epoch: [3/7], Step: [2501/3094], Training Loss: 0.9759833216667175\n",
      "Epoch: [3/7], Step: [2601/3094], Validation Acc: 63.7\n",
      "Epoch: [3/7], Step: [2601/3094], Training Loss: 0.7832343578338623\n",
      "Epoch: [3/7], Step: [2701/3094], Validation Acc: 63.0\n",
      "Epoch: [3/7], Step: [2701/3094], Training Loss: 0.8841428160667419\n",
      "Epoch: [3/7], Step: [2801/3094], Validation Acc: 61.8\n",
      "Epoch: [3/7], Step: [2801/3094], Training Loss: 1.078775405883789\n",
      "Epoch: [3/7], Step: [2901/3094], Validation Acc: 63.3\n",
      "Epoch: [3/7], Step: [2901/3094], Training Loss: 0.8166943788528442\n",
      "Epoch: [3/7], Step: [3001/3094], Validation Acc: 63.7\n",
      "Epoch: [3/7], Step: [3001/3094], Training Loss: 0.8063389658927917\n",
      "Epoch: [4/7], Step: [101/3094], Validation Acc: 64.1\n",
      "Epoch: [4/7], Step: [101/3094], Training Loss: 0.7247499227523804\n",
      "Epoch: [4/7], Step: [201/3094], Validation Acc: 62.5\n",
      "Epoch: [4/7], Step: [201/3094], Training Loss: 0.9711874127388\n",
      "Epoch: [4/7], Step: [301/3094], Validation Acc: 62.8\n",
      "Epoch: [4/7], Step: [301/3094], Training Loss: 0.7651833295822144\n",
      "Epoch: [4/7], Step: [401/3094], Validation Acc: 62.9\n",
      "Epoch: [4/7], Step: [401/3094], Training Loss: 0.7361959218978882\n",
      "Epoch: [4/7], Step: [501/3094], Validation Acc: 62.4\n",
      "Epoch: [4/7], Step: [501/3094], Training Loss: 0.5025981664657593\n",
      "Epoch: [4/7], Step: [601/3094], Validation Acc: 62.3\n",
      "Epoch: [4/7], Step: [601/3094], Training Loss: 1.082148790359497\n",
      "Epoch: [4/7], Step: [701/3094], Validation Acc: 63.4\n",
      "Epoch: [4/7], Step: [701/3094], Training Loss: 0.5904402136802673\n",
      "Epoch: [4/7], Step: [801/3094], Validation Acc: 63.1\n",
      "Epoch: [4/7], Step: [801/3094], Training Loss: 0.6398616433143616\n",
      "Epoch: [4/7], Step: [901/3094], Validation Acc: 63.3\n",
      "Epoch: [4/7], Step: [901/3094], Training Loss: 0.5956584215164185\n",
      "Epoch: [4/7], Step: [1001/3094], Validation Acc: 62.1\n",
      "Epoch: [4/7], Step: [1001/3094], Training Loss: 0.6928014159202576\n",
      "Epoch: [4/7], Step: [1101/3094], Validation Acc: 63.1\n",
      "Epoch: [4/7], Step: [1101/3094], Training Loss: 0.7688562870025635\n",
      "Epoch: [4/7], Step: [1201/3094], Validation Acc: 63.5\n",
      "Epoch: [4/7], Step: [1201/3094], Training Loss: 0.6253710985183716\n",
      "Epoch: [4/7], Step: [1301/3094], Validation Acc: 63.9\n",
      "Epoch: [4/7], Step: [1301/3094], Training Loss: 0.9430350065231323\n",
      "Epoch: [4/7], Step: [1401/3094], Validation Acc: 63.4\n",
      "Epoch: [4/7], Step: [1401/3094], Training Loss: 0.9097736477851868\n",
      "Epoch: [4/7], Step: [1501/3094], Validation Acc: 62.8\n",
      "Epoch: [4/7], Step: [1501/3094], Training Loss: 0.6842289566993713\n",
      "Epoch: [4/7], Step: [1601/3094], Validation Acc: 62.5\n",
      "Epoch: [4/7], Step: [1601/3094], Training Loss: 0.7138964533805847\n",
      "Epoch: [4/7], Step: [1701/3094], Validation Acc: 62.3\n",
      "Epoch: [4/7], Step: [1701/3094], Training Loss: 0.8259058594703674\n",
      "Epoch: [4/7], Step: [1801/3094], Validation Acc: 63.2\n",
      "Epoch: [4/7], Step: [1801/3094], Training Loss: 0.8043522238731384\n",
      "Epoch: [4/7], Step: [1901/3094], Validation Acc: 63.5\n",
      "Epoch: [4/7], Step: [1901/3094], Training Loss: 0.72645503282547\n",
      "Epoch: [4/7], Step: [2001/3094], Validation Acc: 65.3\n",
      "Epoch: [4/7], Step: [2001/3094], Training Loss: 0.543432354927063\n",
      "Epoch: [4/7], Step: [2101/3094], Validation Acc: 64.8\n",
      "Epoch: [4/7], Step: [2101/3094], Training Loss: 0.7861589789390564\n",
      "Epoch: [4/7], Step: [2201/3094], Validation Acc: 62.5\n",
      "Epoch: [4/7], Step: [2201/3094], Training Loss: 0.6300212740898132\n",
      "Epoch: [4/7], Step: [2301/3094], Validation Acc: 62.9\n",
      "Epoch: [4/7], Step: [2301/3094], Training Loss: 0.5854884386062622\n",
      "Epoch: [4/7], Step: [2401/3094], Validation Acc: 63.9\n",
      "Epoch: [4/7], Step: [2401/3094], Training Loss: 0.7303595542907715\n",
      "Epoch: [4/7], Step: [2501/3094], Validation Acc: 62.9\n",
      "Epoch: [4/7], Step: [2501/3094], Training Loss: 0.9037859439849854\n",
      "Epoch: [4/7], Step: [2601/3094], Validation Acc: 64.6\n",
      "Epoch: [4/7], Step: [2601/3094], Training Loss: 0.7318723201751709\n",
      "Epoch: [4/7], Step: [2701/3094], Validation Acc: 63.0\n",
      "Epoch: [4/7], Step: [2701/3094], Training Loss: 0.8720535635948181\n",
      "Epoch: [4/7], Step: [2801/3094], Validation Acc: 61.8\n",
      "Epoch: [4/7], Step: [2801/3094], Training Loss: 1.0648987293243408\n",
      "Epoch: [4/7], Step: [2901/3094], Validation Acc: 63.1\n",
      "Epoch: [4/7], Step: [2901/3094], Training Loss: 0.7929105758666992\n",
      "Epoch: [4/7], Step: [3001/3094], Validation Acc: 64.7\n",
      "Epoch: [4/7], Step: [3001/3094], Training Loss: 0.7789513468742371\n",
      "Epoch: [5/7], Step: [101/3094], Validation Acc: 64.3\n",
      "Epoch: [5/7], Step: [101/3094], Training Loss: 0.6695286631584167\n",
      "Epoch: [5/7], Step: [201/3094], Validation Acc: 63.4\n",
      "Epoch: [5/7], Step: [201/3094], Training Loss: 0.9072082042694092\n",
      "Epoch: [5/7], Step: [301/3094], Validation Acc: 63.1\n",
      "Epoch: [5/7], Step: [301/3094], Training Loss: 0.7730901837348938\n",
      "Epoch: [5/7], Step: [401/3094], Validation Acc: 63.1\n",
      "Epoch: [5/7], Step: [401/3094], Training Loss: 0.674741804599762\n",
      "Epoch: [5/7], Step: [501/3094], Validation Acc: 63.3\n",
      "Epoch: [5/7], Step: [501/3094], Training Loss: 0.4349549114704132\n",
      "Epoch: [5/7], Step: [601/3094], Validation Acc: 63.1\n",
      "Epoch: [5/7], Step: [601/3094], Training Loss: 1.0013055801391602\n",
      "Epoch: [5/7], Step: [701/3094], Validation Acc: 64.4\n",
      "Epoch: [5/7], Step: [701/3094], Training Loss: 0.5783267021179199\n",
      "Epoch: [5/7], Step: [801/3094], Validation Acc: 61.4\n",
      "Epoch: [5/7], Step: [801/3094], Training Loss: 0.6277416944503784\n",
      "Epoch: [5/7], Step: [901/3094], Validation Acc: 63.5\n",
      "Epoch: [5/7], Step: [901/3094], Training Loss: 0.5655938982963562\n",
      "Epoch: [5/7], Step: [1001/3094], Validation Acc: 63.0\n",
      "Epoch: [5/7], Step: [1001/3094], Training Loss: 0.6361550092697144\n",
      "Epoch: [5/7], Step: [1101/3094], Validation Acc: 65.2\n",
      "Epoch: [5/7], Step: [1101/3094], Training Loss: 0.8064263463020325\n",
      "Epoch: [5/7], Step: [1201/3094], Validation Acc: 62.7\n",
      "Epoch: [5/7], Step: [1201/3094], Training Loss: 0.6082395315170288\n",
      "Epoch: [5/7], Step: [1301/3094], Validation Acc: 64.5\n",
      "Epoch: [5/7], Step: [1301/3094], Training Loss: 0.9070426225662231\n",
      "Epoch: [5/7], Step: [1401/3094], Validation Acc: 63.8\n",
      "Epoch: [5/7], Step: [1401/3094], Training Loss: 0.8874183893203735\n",
      "Epoch: [5/7], Step: [1501/3094], Validation Acc: 63.0\n",
      "Epoch: [5/7], Step: [1501/3094], Training Loss: 0.6782156229019165\n",
      "Epoch: [5/7], Step: [1601/3094], Validation Acc: 63.1\n",
      "Epoch: [5/7], Step: [1601/3094], Training Loss: 0.6925870180130005\n",
      "Epoch: [5/7], Step: [1701/3094], Validation Acc: 62.7\n",
      "Epoch: [5/7], Step: [1701/3094], Training Loss: 0.7902973890304565\n",
      "Epoch: [5/7], Step: [1801/3094], Validation Acc: 63.4\n",
      "Epoch: [5/7], Step: [1801/3094], Training Loss: 0.7217057943344116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/7], Step: [1901/3094], Validation Acc: 64.4\n",
      "Epoch: [5/7], Step: [1901/3094], Training Loss: 0.6819231510162354\n",
      "Epoch: [5/7], Step: [2001/3094], Validation Acc: 64.8\n",
      "Epoch: [5/7], Step: [2001/3094], Training Loss: 0.5292691588401794\n",
      "Epoch: [5/7], Step: [2101/3094], Validation Acc: 65.3\n",
      "Epoch: [5/7], Step: [2101/3094], Training Loss: 0.7463434934616089\n",
      "Epoch: [5/7], Step: [2201/3094], Validation Acc: 63.4\n",
      "Epoch: [5/7], Step: [2201/3094], Training Loss: 0.6259404420852661\n",
      "Epoch: [5/7], Step: [2301/3094], Validation Acc: 64.8\n",
      "Epoch: [5/7], Step: [2301/3094], Training Loss: 0.546959400177002\n",
      "Epoch: [5/7], Step: [2401/3094], Validation Acc: 64.1\n",
      "Epoch: [5/7], Step: [2401/3094], Training Loss: 0.6889359951019287\n",
      "Epoch: [5/7], Step: [2501/3094], Validation Acc: 62.4\n",
      "Epoch: [5/7], Step: [2501/3094], Training Loss: 0.8621200323104858\n",
      "Epoch: [5/7], Step: [2601/3094], Validation Acc: 64.3\n",
      "Epoch: [5/7], Step: [2601/3094], Training Loss: 0.8099386692047119\n",
      "Epoch: [5/7], Step: [2701/3094], Validation Acc: 63.4\n",
      "Epoch: [5/7], Step: [2701/3094], Training Loss: 0.8131758570671082\n",
      "Epoch: [5/7], Step: [2801/3094], Validation Acc: 63.5\n",
      "Epoch: [5/7], Step: [2801/3094], Training Loss: 1.0150643587112427\n",
      "Epoch: [5/7], Step: [2901/3094], Validation Acc: 63.8\n",
      "Epoch: [5/7], Step: [2901/3094], Training Loss: 0.7650930881500244\n",
      "Epoch: [5/7], Step: [3001/3094], Validation Acc: 65.1\n",
      "Epoch: [5/7], Step: [3001/3094], Training Loss: 0.769568920135498\n",
      "Epoch: [6/7], Step: [101/3094], Validation Acc: 64.2\n",
      "Epoch: [6/7], Step: [101/3094], Training Loss: 0.661666750907898\n",
      "Epoch: [6/7], Step: [201/3094], Validation Acc: 63.6\n",
      "Epoch: [6/7], Step: [201/3094], Training Loss: 0.9022390842437744\n",
      "Epoch: [6/7], Step: [301/3094], Validation Acc: 63.6\n",
      "Epoch: [6/7], Step: [301/3094], Training Loss: 0.7196320295333862\n",
      "Epoch: [6/7], Step: [401/3094], Validation Acc: 62.4\n",
      "Epoch: [6/7], Step: [401/3094], Training Loss: 0.6489646434783936\n",
      "Epoch: [6/7], Step: [501/3094], Validation Acc: 62.4\n",
      "Epoch: [6/7], Step: [501/3094], Training Loss: 0.40353572368621826\n",
      "Epoch: [6/7], Step: [601/3094], Validation Acc: 63.4\n",
      "Epoch: [6/7], Step: [601/3094], Training Loss: 1.0217360258102417\n",
      "Epoch: [6/7], Step: [701/3094], Validation Acc: 65.3\n",
      "Epoch: [6/7], Step: [701/3094], Training Loss: 0.553729236125946\n",
      "Epoch: [6/7], Step: [801/3094], Validation Acc: 63.7\n",
      "Epoch: [6/7], Step: [801/3094], Training Loss: 0.6012197136878967\n",
      "Epoch: [6/7], Step: [901/3094], Validation Acc: 64.2\n",
      "Epoch: [6/7], Step: [901/3094], Training Loss: 0.5085763335227966\n",
      "Epoch: [6/7], Step: [1001/3094], Validation Acc: 64.5\n",
      "Epoch: [6/7], Step: [1001/3094], Training Loss: 0.6455991864204407\n",
      "Epoch: [6/7], Step: [1101/3094], Validation Acc: 64.6\n",
      "Epoch: [6/7], Step: [1101/3094], Training Loss: 0.8153671622276306\n",
      "Epoch: [6/7], Step: [1201/3094], Validation Acc: 64.0\n",
      "Epoch: [6/7], Step: [1201/3094], Training Loss: 0.5158278942108154\n",
      "Epoch: [6/7], Step: [1301/3094], Validation Acc: 64.4\n",
      "Epoch: [6/7], Step: [1301/3094], Training Loss: 0.8765426278114319\n",
      "Epoch: [6/7], Step: [1401/3094], Validation Acc: 63.2\n",
      "Epoch: [6/7], Step: [1401/3094], Training Loss: 0.8153507113456726\n",
      "Epoch: [6/7], Step: [1501/3094], Validation Acc: 61.9\n",
      "Epoch: [6/7], Step: [1501/3094], Training Loss: 0.6868187189102173\n",
      "Epoch: [6/7], Step: [1601/3094], Validation Acc: 62.8\n",
      "Epoch: [6/7], Step: [1601/3094], Training Loss: 0.6617427468299866\n",
      "Epoch: [6/7], Step: [1701/3094], Validation Acc: 62.9\n",
      "Epoch: [6/7], Step: [1701/3094], Training Loss: 0.7815051674842834\n",
      "Epoch: [6/7], Step: [1801/3094], Validation Acc: 62.3\n",
      "Epoch: [6/7], Step: [1801/3094], Training Loss: 0.6534855365753174\n",
      "Epoch: [6/7], Step: [1901/3094], Validation Acc: 63.9\n",
      "Epoch: [6/7], Step: [1901/3094], Training Loss: 0.6884479522705078\n",
      "Epoch: [6/7], Step: [2001/3094], Validation Acc: 65.1\n",
      "Epoch: [6/7], Step: [2001/3094], Training Loss: 0.5100160241127014\n",
      "Epoch: [6/7], Step: [2101/3094], Validation Acc: 64.6\n",
      "Epoch: [6/7], Step: [2101/3094], Training Loss: 0.6877095699310303\n",
      "Epoch: [6/7], Step: [2201/3094], Validation Acc: 63.4\n",
      "Epoch: [6/7], Step: [2201/3094], Training Loss: 0.6361457109451294\n",
      "Epoch: [6/7], Step: [2301/3094], Validation Acc: 64.0\n",
      "Epoch: [6/7], Step: [2301/3094], Training Loss: 0.48981818556785583\n",
      "Epoch: [6/7], Step: [2401/3094], Validation Acc: 63.8\n",
      "Epoch: [6/7], Step: [2401/3094], Training Loss: 0.6978861093521118\n",
      "Epoch: [6/7], Step: [2501/3094], Validation Acc: 64.0\n",
      "Epoch: [6/7], Step: [2501/3094], Training Loss: 0.825153112411499\n",
      "Epoch: [6/7], Step: [2601/3094], Validation Acc: 64.6\n",
      "Epoch: [6/7], Step: [2601/3094], Training Loss: 0.7785233855247498\n",
      "Epoch: [6/7], Step: [2701/3094], Validation Acc: 63.4\n",
      "Epoch: [6/7], Step: [2701/3094], Training Loss: 0.8006606698036194\n",
      "Epoch: [6/7], Step: [2801/3094], Validation Acc: 62.5\n",
      "Epoch: [6/7], Step: [2801/3094], Training Loss: 0.937976062297821\n",
      "Epoch: [6/7], Step: [2901/3094], Validation Acc: 64.3\n",
      "Epoch: [6/7], Step: [2901/3094], Training Loss: 0.7301665544509888\n",
      "Epoch: [6/7], Step: [3001/3094], Validation Acc: 64.5\n",
      "Epoch: [6/7], Step: [3001/3094], Training Loss: 0.733065128326416\n",
      "Epoch: [7/7], Step: [101/3094], Validation Acc: 63.1\n",
      "Epoch: [7/7], Step: [101/3094], Training Loss: 0.6213998794555664\n",
      "Epoch: [7/7], Step: [201/3094], Validation Acc: 63.5\n",
      "Epoch: [7/7], Step: [201/3094], Training Loss: 0.8834420442581177\n",
      "Epoch: [7/7], Step: [301/3094], Validation Acc: 63.3\n",
      "Epoch: [7/7], Step: [301/3094], Training Loss: 0.6104399561882019\n",
      "Epoch: [7/7], Step: [401/3094], Validation Acc: 63.1\n",
      "Epoch: [7/7], Step: [401/3094], Training Loss: 0.5767595767974854\n",
      "Epoch: [7/7], Step: [501/3094], Validation Acc: 62.6\n",
      "Epoch: [7/7], Step: [501/3094], Training Loss: 0.41400325298309326\n",
      "Epoch: [7/7], Step: [601/3094], Validation Acc: 63.3\n",
      "Epoch: [7/7], Step: [601/3094], Training Loss: 0.9904564619064331\n",
      "Epoch: [7/7], Step: [701/3094], Validation Acc: 64.9\n",
      "Epoch: [7/7], Step: [701/3094], Training Loss: 0.5077409744262695\n",
      "Epoch: [7/7], Step: [801/3094], Validation Acc: 61.7\n",
      "Epoch: [7/7], Step: [801/3094], Training Loss: 0.5972151160240173\n",
      "Epoch: [7/7], Step: [901/3094], Validation Acc: 64.5\n",
      "Epoch: [7/7], Step: [901/3094], Training Loss: 0.4409841299057007\n",
      "Epoch: [7/7], Step: [1001/3094], Validation Acc: 62.9\n",
      "Epoch: [7/7], Step: [1001/3094], Training Loss: 0.645927906036377\n",
      "Epoch: [7/7], Step: [1101/3094], Validation Acc: 64.2\n",
      "Epoch: [7/7], Step: [1101/3094], Training Loss: 0.7551414966583252\n",
      "Epoch: [7/7], Step: [1201/3094], Validation Acc: 63.7\n",
      "Epoch: [7/7], Step: [1201/3094], Training Loss: 0.5594989061355591\n",
      "Epoch: [7/7], Step: [1301/3094], Validation Acc: 64.0\n",
      "Epoch: [7/7], Step: [1301/3094], Training Loss: 0.8189696669578552\n",
      "Epoch: [7/7], Step: [1401/3094], Validation Acc: 63.2\n",
      "Epoch: [7/7], Step: [1401/3094], Training Loss: 0.749249279499054\n",
      "Epoch: [7/7], Step: [1501/3094], Validation Acc: 62.3\n",
      "Epoch: [7/7], Step: [1501/3094], Training Loss: 0.6227695345878601\n",
      "Epoch: [7/7], Step: [1601/3094], Validation Acc: 62.5\n",
      "Epoch: [7/7], Step: [1601/3094], Training Loss: 0.7009103894233704\n",
      "Epoch: [7/7], Step: [1701/3094], Validation Acc: 62.3\n",
      "Epoch: [7/7], Step: [1701/3094], Training Loss: 0.7809875011444092\n",
      "Epoch: [7/7], Step: [1801/3094], Validation Acc: 63.1\n",
      "Epoch: [7/7], Step: [1801/3094], Training Loss: 0.6583320498466492\n",
      "Epoch: [7/7], Step: [1901/3094], Validation Acc: 64.1\n",
      "Epoch: [7/7], Step: [1901/3094], Training Loss: 0.6592702269554138\n",
      "Epoch: [7/7], Step: [2001/3094], Validation Acc: 64.0\n",
      "Epoch: [7/7], Step: [2001/3094], Training Loss: 0.46186119318008423\n",
      "Epoch: [7/7], Step: [2101/3094], Validation Acc: 64.0\n",
      "Epoch: [7/7], Step: [2101/3094], Training Loss: 0.645451545715332\n",
      "Epoch: [7/7], Step: [2201/3094], Validation Acc: 62.7\n",
      "Epoch: [7/7], Step: [2201/3094], Training Loss: 0.55340176820755\n",
      "Epoch: [7/7], Step: [2301/3094], Validation Acc: 62.0\n",
      "Epoch: [7/7], Step: [2301/3094], Training Loss: 0.516310453414917\n",
      "Epoch: [7/7], Step: [2401/3094], Validation Acc: 64.7\n",
      "Epoch: [7/7], Step: [2401/3094], Training Loss: 0.6667410731315613\n",
      "Epoch: [7/7], Step: [2501/3094], Validation Acc: 64.9\n",
      "Epoch: [7/7], Step: [2501/3094], Training Loss: 0.8550484776496887\n",
      "Epoch: [7/7], Step: [2601/3094], Validation Acc: 63.4\n",
      "Epoch: [7/7], Step: [2601/3094], Training Loss: 0.7211189866065979\n",
      "Epoch: [7/7], Step: [2701/3094], Validation Acc: 62.5\n",
      "Epoch: [7/7], Step: [2701/3094], Training Loss: 0.7504063248634338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/7], Step: [2801/3094], Validation Acc: 62.1\n",
      "Epoch: [7/7], Step: [2801/3094], Training Loss: 0.9613803625106812\n",
      "Epoch: [7/7], Step: [2901/3094], Validation Acc: 63.6\n",
      "Epoch: [7/7], Step: [2901/3094], Training Loss: 0.7707784175872803\n",
      "Epoch: [7/7], Step: [3001/3094], Validation Acc: 64.1\n",
      "Epoch: [7/7], Step: [3001/3094], Training Loss: 0.6876821517944336\n"
     ]
    }
   ],
   "source": [
    "model = CNN(emb_size = 300, hidden_size=200, num_layers=1, num_classes=3).cuda()\n",
    "train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Ideas\n",
    "###\n",
    "\n",
    "# Dropout layers --> prob 0.5\n",
    "# weight decay. \n",
    "\n",
    "#rnn --> layer normalize\n",
    "\n",
    "# CNN masking\n",
    "# do not backpropagate\n",
    "# after conv, cresate tensor masked not update.\n",
    "# right after regular linear layer\n",
    "# \n",
    "# set all elements until padding to 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
