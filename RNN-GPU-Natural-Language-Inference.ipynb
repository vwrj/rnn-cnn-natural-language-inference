{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please find the 3 correct and 3 incorrect predictions at the bottom of this notebook. Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "import io\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for each step in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    print(n, d)\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        if i == VOCAB_SIZE:\n",
    "            break\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "        i += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "VOCAB_SIZE = 50000\n",
    "\n",
    "def build_vocab():\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    word_vectors = pkl.load(open(\"fasttext_word_vectors.p\", \"rb\"))\n",
    "    id2token = list(word_vectors.keys())\n",
    "    token2id = dict(zip(word_vectors, range(2,2+len(word_vectors)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return word_vectors, token2id, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels_to_integers(data_label):\n",
    "    for i in range(len(data_label)):\n",
    "        if data_label[i] == \"contradiction\":\n",
    "            data_label[i] = 0\n",
    "        elif data_label[i] == \"entailment\":\n",
    "            data_label[i] = 1\n",
    "        elif data_label[i] == \"neutral\":\n",
    "            data_label[i] = 2\n",
    "    return data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_order(sent1_data, sent2_data, data_label):\n",
    "    i = random.randint(1, len(sent1_data))\n",
    "    print(sent1_data[i])\n",
    "    print(sent2_data[i])\n",
    "    print(data_label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenize each entry in a list of sentences\n",
    "def tokenize(sentence_list):\n",
    "    return [word_tokenize(sentence_list[i]) for i in range(len(sentence_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"one-hot encode\": convert each token to id in vocabulary vector (token2id)\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vocabulary & embedding matrix from FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors, token2id, id2token = build_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50002, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_weights = np.array(list(word_vectors.values()))\n",
    "pad_vec = np.zeros((1, 300))\n",
    "unk_vec = np.random.randn(1, 300) * 0.01\n",
    "pad_unk_vecs = np.vstack((pad_vec, unk_vec))\n",
    "_WEIGHTS = np.vstack((pad_unk_vecs, _weights))\n",
    "_WEIGHTS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to pre-process data for TwoSentenceModel\n",
    "#### Shuffle, word tokenize, one-hot index into vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(sent1s, sent2s, labels, verify=True):\n",
    "    labels = convert_labels_to_integers(labels)\n",
    "    seed = random.randint(1, 100)\n",
    "    print(\"Random seed for shuffling: {}\".format(seed))\n",
    "    random.Random(seed).shuffle(sent1s)\n",
    "    random.Random(seed).shuffle(sent2s)\n",
    "    random.Random(seed).shuffle(labels)\n",
    "    \n",
    "    print(\"\\nVerifying that the data and label match after shuffling\")\n",
    "    if verify:\n",
    "        verify_order(sent1s, sent2s, labels)\n",
    "        verify_order(sent1s, sent2s, labels)\n",
    "          \n",
    "    print(\"\\nTokenizing sentence 1 list...\")    \n",
    "    sent1s_tokenized = tokenize(sent1s)\n",
    "    print(\"done!\")\n",
    "    print(\"\\nTokenizing sentence 2 list... \")  \n",
    "    sent2s_tokenized = tokenize(sent2s)\n",
    "    print(\"done!\")\n",
    "    \n",
    "    print(\"\\nOne-hot encoding words for sentence 1 list...\")  \n",
    "    sent1s_indices = token2index_dataset(sent1s_tokenized)\n",
    "    print(\"done!\")\n",
    "    print(\"\\nOne-hot encoding words for sentence 2 list...\")  \n",
    "    sent2s_indices = token2index_dataset(sent2s_tokenized)\n",
    "    print(\"done!\")\n",
    "    \n",
    "    return (sent1s_indices, sent2s_indices, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_SENTENCE_LENGTH = 30\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TwoSentencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sent1_data_list, sent2_data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param sent1_data_list: list of sentence1's (index matches sentence2's and target_list below)\n",
    "        @param sent2_data_list: list of sentence2's\n",
    "        @param target_list: list of correct labels\n",
    "\n",
    "        \"\"\"\n",
    "        self.sent1_data_list = sent1_data_list\n",
    "        self.sent2_data_list = sent2_data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.sent1_data_list) == len(self.target_list) and len(self.sent2_data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sent1_data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        ###\n",
    "        ### Returns [[sentence, 1, tokens], [sentence, 2, tokens]]\n",
    "        ###\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        sent1_tokens_idx = self.sent1_data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        sent2_tokens_idx = self.sent2_data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        combined_tokens_idx = [sent1_tokens_idx, sent2_tokens_idx]\n",
    "        label = self.target_list[key]\n",
    "        return [combined_tokens_idx, len(sent1_tokens_idx), len(sent2_tokens_idx), label]\n",
    "\n",
    "def twosentences_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    sent1_data_list = []\n",
    "    sent2_data_list = []\n",
    "    sent1_length_list = []\n",
    "    sent2_length_list = []\n",
    "    label_list = []\n",
    "    combined_data_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[3])\n",
    "        sent1_length_list.append(datum[1])\n",
    "        sent2_length_list.append(datum[2])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_1 = np.pad(np.array(datum[0][0]), pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_2 = np.pad(np.array(datum[0][1]), pad_width=((0,MAX_SENTENCE_LENGTH-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        combined_data_list.append([padded_vec_1, padded_vec_2])\n",
    "    return [torch.from_numpy(np.array(combined_data_list)), \n",
    "            torch.LongTensor(sent1_length_list), torch.LongTensor(sent2_length_list), torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: 100000\n"
     ]
    }
   ],
   "source": [
    "snli_train = pd.read_csv('snli_train.tsv', sep='\\t')\n",
    "TRAIN_SIZE = 100000\n",
    "\n",
    "sent1_data = list(snli_train[\"sentence1\"])[:TRAIN_SIZE]\n",
    "sent2_data = list(snli_train[\"sentence2\"])[:TRAIN_SIZE]\n",
    "data_label = list(snli_train[\"label\"])[:TRAIN_SIZE]\n",
    "print(\"Size of training data: {}\".format(len(sent1_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed for shuffling: 44\n",
      "\n",
      "Verifying that the data and label match after shuffling\n",
      "Young people are walking on the street in the evening .\n",
      "Some people are outside\n",
      "2\n",
      "Four women are in the middle of a dance routine on a game court .\n",
      "Four women are performing in the middle of a court .\n",
      "2\n",
      "\n",
      "Tokenizing sentence 1 list...\n",
      "done!\n",
      "\n",
      "Tokenizing sentence 2 list... \n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 1 list...\n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 2 list...\n",
      "done!\n",
      "Finished creating train_loader.\n"
     ]
    }
   ],
   "source": [
    "sent1_train_indices, sent2_train_indices, train_label = data_pipeline(sent1_data, sent2_data, data_label)\n",
    "train_dataset = TwoSentencesDataset(sent1_train_indices, sent2_train_indices, train_label)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           collate_fn=twosentences_collate_func,\n",
    "                                           #shuffle=True\n",
    "                                          )\n",
    "print(\"Finished creating train_loader.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of val data: 1000\n"
     ]
    }
   ],
   "source": [
    "snli_val = pd.read_csv('snli_val.tsv', sep='\\t')\n",
    "sent1_val = list(snli_val[\"sentence1\"])\n",
    "sent2_val = list(snli_val[\"sentence2\"])\n",
    "val_label = list(snli_val[\"label\"])\n",
    "print(\"Size of val data: {}\".format(len(sent1_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed for shuffling: 96\n",
      "\n",
      "Verifying that the data and label match after shuffling\n",
      "A nurse examines equipment in the operating room .\n",
      "A nurse at work .\n",
      "1\n",
      "Two women both dressed in white tops and dark-colored shorts are standing in front of some motorcycles on a city street\n",
      "One woman and one man stand in front of a new car while wearing green sweaters .\n",
      "0\n",
      "\n",
      "Tokenizing sentence 1 list...\n",
      "done!\n",
      "\n",
      "Tokenizing sentence 2 list... \n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 1 list...\n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 2 list...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "sent1_val_indices, sent2_val_indices, val_label = data_pipeline(sent1_val, sent2_val, val_label)\n",
    "val_dataset = TwoSentencesDataset(sent1_val_indices, sent2_val_indices, val_label)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           collate_fn=twosentences_collate_func,\n",
    "                                           #shuffle=True\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([len(x) for x in snli_train['sentence1']]).describe()['75%']\n",
    "MAX_SENTENCE_LENGTH = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoSentenceModel(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, num_classes, emb_size = 300):\n",
    "        # RNN Accepts the following hyperparams:\n",
    "        # emb_size: Embedding Size\n",
    "        # hidden_size: Hidden Size of layer in RNN\n",
    "        # num_layers: number of layers in RNN\n",
    "        # num_classes: number of output classes\n",
    "        # vocab_size: vocabulary size\n",
    "        super(TwoSentenceModel, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        weight = torch.FloatTensor(_WEIGHTS)\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "#         self.rnn = nn.RNN(emb_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.linear = nn.Linear(2*hidden_size, num_classes)\n",
    "        # TRYING GRU, UNCOMMENT Below if doing GRU\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear1 = nn.Linear(2*hidden_size, 100)\n",
    "        self.linear2 = nn.Linear(100, num_classes)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Function initializes the activation of recurrent neural net at timestep 0\n",
    "        # Needs to be in format (num_layers, batch_size, hidden_size)\n",
    "        return torch.randn(2, batch_size*2, self.hidden_size).to(device)\n",
    "\n",
    "    def forward(self, x, sent1_lengths, sent2_lengths):\n",
    "        # reset hidden state\n",
    "        batch_size = x.size()[0]\n",
    "                \n",
    "        s1lengths = list(sent1_lengths)\n",
    "        s2lengths = list(sent2_lengths)\n",
    "        ordered_slengths = s1lengths + s2lengths\n",
    "\n",
    "        reverse_sorted_indices = [x for _, x in sorted(zip(ordered_slengths, range(len(ordered_slengths))), reverse=True)]\n",
    "        reverse_sorted_lengths = [x for x, _ in sorted(zip(ordered_slengths, range(len(ordered_slengths))), reverse=True)]\n",
    "        reverse_sorted_lengths = np.array(reverse_sorted_lengths)\n",
    "        \n",
    "        sent1s = x[:, 0, :]\n",
    "        sent2s = x[:, 1, :]\n",
    "        ordered_sents = torch.cat([sent1s, sent2s], dim=0).to(device)\n",
    "        reverse_sorted_data = torch.index_select(ordered_sents, 0, torch.tensor(reverse_sorted_indices).to(device))\n",
    "        \n",
    "        # get embedding\n",
    "        embed = self.embedding(reverse_sorted_data)\n",
    "        \n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # pack padded sequence\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed, reverse_sorted_lengths, batch_first=True)\n",
    "              \n",
    "        # fprop though RNN\n",
    "        rnn_out, self.hidden = self.rnn(embed, self.hidden)\n",
    "                \n",
    "        ### MATCHING BACK\n",
    "        change_it_back = [x for _, x in sorted(zip(reverse_sorted_indices, range(len(reverse_sorted_indices))))]\n",
    "        self.hidden = torch.index_select(self.hidden, 1, torch.LongTensor(change_it_back).to(device)) \n",
    "        \n",
    "        # 2 by 64 by 250. back in the right order that it came in.        \n",
    "#         hidden_sent1s = self.hidden[0, 0:batch_size, :]\n",
    "#         hidden_sent2s = self.hidden[0, batch_size:, :]\n",
    "              \n",
    "        ### GRU stuff\n",
    "        hidden_sent1s = torch.cat([self.hidden[0, 0:batch_size, :], self.hidden[1, 0:batch_size, :]], dim=1)\n",
    "        hidden_sent2s = torch.cat([self.hidden[0, batch_size:, :], self.hidden[1, batch_size:, :]], dim=1)\n",
    "        \n",
    "#         concatenation of encoded sentences\n",
    "#         linear1 = self.linear1(torch.cat([hidden_sent1s, hidden_sent2s], dim=1))\n",
    "#         addition of encoded sentences\n",
    "#         linear1 = self.linear1(torch.tensor(hidden_sent1s) + torch.tensor(hidden_sent2s))\n",
    "#         element-wise multiplication of encoded sentences\n",
    "        linear1 = self.linear1(torch.tensor(hidden_sent1s)*torch.tensor(hidden_sent2s))\n",
    "        linear1 = F.relu(linear1.contiguous().view(-1, linear1.size(-1))).view(linear1.shape)   \n",
    "#         linear1 = self.dropout(linear1)\n",
    "        logits = self.linear2(linear1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Helper function that tests the model's performance on a dataset\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for (data, sent1_lengths, sent2_lengths, labels) in loader:\n",
    "        data_batch, sent1_length_batch, sent2_length_batch, label_batch = data.to(device), sent1_lengths.to(device), sent2_lengths.to(device), labels.to(device)\n",
    "        outputs = F.softmax(model(data_batch, sent1_length_batch, sent2_length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        labels = labels.to(device)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "def train_model(model, lr = 0.001, num_epochs = 7, criterion = nn.CrossEntropyLoss()):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
    "    max_val_acc = 0\n",
    "    losses = []\n",
    "    xs = 0\n",
    "    val_accs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, sent1_lengths, sent2_lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, sent1_length_batch, sent2_length_batch, label_batch = data.to(device), sent1_lengths.to(device), sent2_lengths.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, sent1_length_batch, sent2_length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 100 iterations\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                val_accs.append(val_acc)\n",
    "                xs += 100\n",
    "                if val_acc > max_val_acc:\n",
    "                    max_val_acc = val_acc\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Training Loss: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), loss))\n",
    "                \n",
    "    print(\"Max Validation Accuracy: {}\".format(max_val_acc))\n",
    "    return max_val_acc, losses, xs, val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting training (loss) and validation (accuracy) curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_validation_curves(losses, xs, val_accs, title):\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    loss_avg_vals = []\n",
    "    for i in range(0, len(losses)-100, 100):\n",
    "        s = 0\n",
    "        avg = 0\n",
    "        for j in range(i, i+100):\n",
    "            s += losses[j]\n",
    "        avg = s/100.0\n",
    "        loss_avg_vals.append(avg)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(len(loss_avg_vals)), loss_avg_vals)\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Average Train Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0, xs, 100), val_accs)\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Val Acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/6], Step: [101/3125], Validation Acc: 33.8\n",
      "Epoch: [1/6], Step: [101/3125], Training Loss: 1.0877712965011597\n",
      "Epoch: [1/6], Step: [201/3125], Validation Acc: 34.8\n",
      "Epoch: [1/6], Step: [201/3125], Training Loss: 1.0994783639907837\n",
      "Epoch: [1/6], Step: [301/3125], Validation Acc: 38.1\n",
      "Epoch: [1/6], Step: [301/3125], Training Loss: 1.10474693775177\n",
      "Epoch: [1/6], Step: [401/3125], Validation Acc: 37.0\n",
      "Epoch: [1/6], Step: [401/3125], Training Loss: 1.118760585784912\n",
      "Epoch: [1/6], Step: [501/3125], Validation Acc: 40.2\n",
      "Epoch: [1/6], Step: [501/3125], Training Loss: 1.0580886602401733\n",
      "Epoch: [1/6], Step: [601/3125], Validation Acc: 40.3\n",
      "Epoch: [1/6], Step: [601/3125], Training Loss: 1.1234210729599\n",
      "Epoch: [1/6], Step: [701/3125], Validation Acc: 41.0\n",
      "Epoch: [1/6], Step: [701/3125], Training Loss: 1.1204242706298828\n",
      "Epoch: [1/6], Step: [801/3125], Validation Acc: 39.8\n",
      "Epoch: [1/6], Step: [801/3125], Training Loss: 1.1243425607681274\n",
      "Epoch: [1/6], Step: [901/3125], Validation Acc: 42.8\n",
      "Epoch: [1/6], Step: [901/3125], Training Loss: 1.0798853635787964\n",
      "Epoch: [1/6], Step: [1001/3125], Validation Acc: 44.1\n",
      "Epoch: [1/6], Step: [1001/3125], Training Loss: 1.0047134160995483\n",
      "Epoch: [1/6], Step: [1101/3125], Validation Acc: 42.4\n",
      "Epoch: [1/6], Step: [1101/3125], Training Loss: 1.1935852766036987\n",
      "Epoch: [1/6], Step: [1201/3125], Validation Acc: 45.0\n",
      "Epoch: [1/6], Step: [1201/3125], Training Loss: 1.0095899105072021\n",
      "Epoch: [1/6], Step: [1301/3125], Validation Acc: 47.1\n",
      "Epoch: [1/6], Step: [1301/3125], Training Loss: 0.9360954761505127\n",
      "Epoch: [1/6], Step: [1401/3125], Validation Acc: 45.1\n",
      "Epoch: [1/6], Step: [1401/3125], Training Loss: 1.0564576387405396\n",
      "Epoch: [1/6], Step: [1501/3125], Validation Acc: 45.4\n",
      "Epoch: [1/6], Step: [1501/3125], Training Loss: 0.9183318614959717\n",
      "Epoch: [1/6], Step: [1601/3125], Validation Acc: 48.8\n",
      "Epoch: [1/6], Step: [1601/3125], Training Loss: 1.0453816652297974\n",
      "Epoch: [1/6], Step: [1701/3125], Validation Acc: 51.6\n",
      "Epoch: [1/6], Step: [1701/3125], Training Loss: 1.021877408027649\n",
      "Epoch: [1/6], Step: [1801/3125], Validation Acc: 49.9\n",
      "Epoch: [1/6], Step: [1801/3125], Training Loss: 1.039434552192688\n",
      "Epoch: [1/6], Step: [1901/3125], Validation Acc: 47.2\n",
      "Epoch: [1/6], Step: [1901/3125], Training Loss: 1.075671672821045\n",
      "Epoch: [1/6], Step: [2001/3125], Validation Acc: 52.7\n",
      "Epoch: [1/6], Step: [2001/3125], Training Loss: 0.9601631164550781\n",
      "Epoch: [1/6], Step: [2101/3125], Validation Acc: 52.4\n",
      "Epoch: [1/6], Step: [2101/3125], Training Loss: 0.9457136988639832\n",
      "Epoch: [1/6], Step: [2201/3125], Validation Acc: 53.6\n",
      "Epoch: [1/6], Step: [2201/3125], Training Loss: 0.9101954102516174\n",
      "Epoch: [1/6], Step: [2301/3125], Validation Acc: 53.6\n",
      "Epoch: [1/6], Step: [2301/3125], Training Loss: 0.9597569108009338\n",
      "Epoch: [1/6], Step: [2401/3125], Validation Acc: 56.5\n",
      "Epoch: [1/6], Step: [2401/3125], Training Loss: 1.0192930698394775\n",
      "Epoch: [1/6], Step: [2501/3125], Validation Acc: 55.7\n",
      "Epoch: [1/6], Step: [2501/3125], Training Loss: 0.9460541009902954\n",
      "Epoch: [1/6], Step: [2601/3125], Validation Acc: 56.3\n",
      "Epoch: [1/6], Step: [2601/3125], Training Loss: 1.1059199571609497\n",
      "Epoch: [1/6], Step: [2701/3125], Validation Acc: 55.0\n",
      "Epoch: [1/6], Step: [2701/3125], Training Loss: 1.0463106632232666\n",
      "Epoch: [1/6], Step: [2801/3125], Validation Acc: 54.3\n",
      "Epoch: [1/6], Step: [2801/3125], Training Loss: 0.9464369416236877\n",
      "Epoch: [1/6], Step: [2901/3125], Validation Acc: 56.8\n",
      "Epoch: [1/6], Step: [2901/3125], Training Loss: 1.0828042030334473\n",
      "Epoch: [1/6], Step: [3001/3125], Validation Acc: 56.2\n",
      "Epoch: [1/6], Step: [3001/3125], Training Loss: 0.9270375967025757\n",
      "Epoch: [1/6], Step: [3101/3125], Validation Acc: 57.0\n",
      "Epoch: [1/6], Step: [3101/3125], Training Loss: 0.9038435816764832\n",
      "Epoch: [2/6], Step: [101/3125], Validation Acc: 57.3\n",
      "Epoch: [2/6], Step: [101/3125], Training Loss: 1.006553292274475\n",
      "Epoch: [2/6], Step: [201/3125], Validation Acc: 56.3\n",
      "Epoch: [2/6], Step: [201/3125], Training Loss: 0.7761488556861877\n",
      "Epoch: [2/6], Step: [301/3125], Validation Acc: 56.5\n",
      "Epoch: [2/6], Step: [301/3125], Training Loss: 0.8376097083091736\n",
      "Epoch: [2/6], Step: [401/3125], Validation Acc: 58.1\n",
      "Epoch: [2/6], Step: [401/3125], Training Loss: 0.8726431727409363\n",
      "Epoch: [2/6], Step: [501/3125], Validation Acc: 59.0\n",
      "Epoch: [2/6], Step: [501/3125], Training Loss: 0.9683493375778198\n",
      "Epoch: [2/6], Step: [601/3125], Validation Acc: 58.1\n",
      "Epoch: [2/6], Step: [601/3125], Training Loss: 1.039443850517273\n",
      "Epoch: [2/6], Step: [701/3125], Validation Acc: 57.5\n",
      "Epoch: [2/6], Step: [701/3125], Training Loss: 0.8966276049613953\n",
      "Epoch: [2/6], Step: [801/3125], Validation Acc: 59.4\n",
      "Epoch: [2/6], Step: [801/3125], Training Loss: 0.8578475713729858\n",
      "Epoch: [2/6], Step: [901/3125], Validation Acc: 57.9\n",
      "Epoch: [2/6], Step: [901/3125], Training Loss: 0.792069673538208\n",
      "Epoch: [2/6], Step: [1001/3125], Validation Acc: 58.6\n",
      "Epoch: [2/6], Step: [1001/3125], Training Loss: 0.7982994318008423\n",
      "Epoch: [2/6], Step: [1101/3125], Validation Acc: 58.4\n",
      "Epoch: [2/6], Step: [1101/3125], Training Loss: 0.9269113540649414\n",
      "Epoch: [2/6], Step: [1201/3125], Validation Acc: 59.3\n",
      "Epoch: [2/6], Step: [1201/3125], Training Loss: 0.7851248383522034\n",
      "Epoch: [2/6], Step: [1301/3125], Validation Acc: 59.7\n",
      "Epoch: [2/6], Step: [1301/3125], Training Loss: 0.6484711766242981\n",
      "Epoch: [2/6], Step: [1401/3125], Validation Acc: 58.9\n",
      "Epoch: [2/6], Step: [1401/3125], Training Loss: 0.8384429216384888\n",
      "Epoch: [2/6], Step: [1501/3125], Validation Acc: 59.0\n",
      "Epoch: [2/6], Step: [1501/3125], Training Loss: 0.6600373983383179\n",
      "Epoch: [2/6], Step: [1601/3125], Validation Acc: 60.7\n",
      "Epoch: [2/6], Step: [1601/3125], Training Loss: 0.8625363111495972\n",
      "Epoch: [2/6], Step: [1701/3125], Validation Acc: 58.8\n",
      "Epoch: [2/6], Step: [1701/3125], Training Loss: 0.7512528896331787\n",
      "Epoch: [2/6], Step: [1801/3125], Validation Acc: 61.4\n",
      "Epoch: [2/6], Step: [1801/3125], Training Loss: 1.0429238080978394\n",
      "Epoch: [2/6], Step: [1901/3125], Validation Acc: 58.4\n",
      "Epoch: [2/6], Step: [1901/3125], Training Loss: 0.9926024675369263\n",
      "Epoch: [2/6], Step: [2001/3125], Validation Acc: 61.5\n",
      "Epoch: [2/6], Step: [2001/3125], Training Loss: 0.7946653366088867\n",
      "Epoch: [2/6], Step: [2101/3125], Validation Acc: 61.7\n",
      "Epoch: [2/6], Step: [2101/3125], Training Loss: 0.7636063694953918\n",
      "Epoch: [2/6], Step: [2201/3125], Validation Acc: 61.6\n",
      "Epoch: [2/6], Step: [2201/3125], Training Loss: 0.7253037691116333\n",
      "Epoch: [2/6], Step: [2301/3125], Validation Acc: 61.3\n",
      "Epoch: [2/6], Step: [2301/3125], Training Loss: 0.8050304055213928\n",
      "Epoch: [2/6], Step: [2401/3125], Validation Acc: 61.2\n",
      "Epoch: [2/6], Step: [2401/3125], Training Loss: 0.9619137048721313\n",
      "Epoch: [2/6], Step: [2501/3125], Validation Acc: 62.2\n",
      "Epoch: [2/6], Step: [2501/3125], Training Loss: 0.851186215877533\n",
      "Epoch: [2/6], Step: [2601/3125], Validation Acc: 62.2\n",
      "Epoch: [2/6], Step: [2601/3125], Training Loss: 0.9525759220123291\n",
      "Epoch: [2/6], Step: [2701/3125], Validation Acc: 60.1\n",
      "Epoch: [2/6], Step: [2701/3125], Training Loss: 0.9860445261001587\n",
      "Epoch: [2/6], Step: [2801/3125], Validation Acc: 62.7\n",
      "Epoch: [2/6], Step: [2801/3125], Training Loss: 0.6897209286689758\n",
      "Epoch: [2/6], Step: [2901/3125], Validation Acc: 63.8\n",
      "Epoch: [2/6], Step: [2901/3125], Training Loss: 1.0297539234161377\n",
      "Epoch: [2/6], Step: [3001/3125], Validation Acc: 61.6\n",
      "Epoch: [2/6], Step: [3001/3125], Training Loss: 0.8999374508857727\n",
      "Epoch: [2/6], Step: [3101/3125], Validation Acc: 62.8\n",
      "Epoch: [2/6], Step: [3101/3125], Training Loss: 0.862510621547699\n",
      "Epoch: [3/6], Step: [101/3125], Validation Acc: 63.2\n",
      "Epoch: [3/6], Step: [101/3125], Training Loss: 0.86863774061203\n",
      "Epoch: [3/6], Step: [201/3125], Validation Acc: 63.0\n",
      "Epoch: [3/6], Step: [201/3125], Training Loss: 0.6882506608963013\n",
      "Epoch: [3/6], Step: [301/3125], Validation Acc: 59.9\n",
      "Epoch: [3/6], Step: [301/3125], Training Loss: 0.6835705041885376\n",
      "Epoch: [3/6], Step: [401/3125], Validation Acc: 62.1\n",
      "Epoch: [3/6], Step: [401/3125], Training Loss: 0.6767603158950806\n",
      "Epoch: [3/6], Step: [501/3125], Validation Acc: 63.5\n",
      "Epoch: [3/6], Step: [501/3125], Training Loss: 0.7884337306022644\n",
      "Epoch: [3/6], Step: [601/3125], Validation Acc: 63.0\n",
      "Epoch: [3/6], Step: [601/3125], Training Loss: 0.8278708457946777\n",
      "Epoch: [3/6], Step: [701/3125], Validation Acc: 63.5\n",
      "Epoch: [3/6], Step: [701/3125], Training Loss: 0.8214274048805237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/6], Step: [801/3125], Validation Acc: 62.8\n",
      "Epoch: [3/6], Step: [801/3125], Training Loss: 0.8197238445281982\n",
      "Epoch: [3/6], Step: [901/3125], Validation Acc: 60.5\n",
      "Epoch: [3/6], Step: [901/3125], Training Loss: 0.708613932132721\n",
      "Epoch: [3/6], Step: [1001/3125], Validation Acc: 61.8\n",
      "Epoch: [3/6], Step: [1001/3125], Training Loss: 0.7393245697021484\n",
      "Epoch: [3/6], Step: [1101/3125], Validation Acc: 63.1\n",
      "Epoch: [3/6], Step: [1101/3125], Training Loss: 0.7754892110824585\n",
      "Epoch: [3/6], Step: [1201/3125], Validation Acc: 62.4\n",
      "Epoch: [3/6], Step: [1201/3125], Training Loss: 0.7050778865814209\n",
      "Epoch: [3/6], Step: [1301/3125], Validation Acc: 63.6\n",
      "Epoch: [3/6], Step: [1301/3125], Training Loss: 0.549340546131134\n",
      "Epoch: [3/6], Step: [1401/3125], Validation Acc: 63.1\n",
      "Epoch: [3/6], Step: [1401/3125], Training Loss: 0.7518320679664612\n",
      "Epoch: [3/6], Step: [1501/3125], Validation Acc: 64.3\n",
      "Epoch: [3/6], Step: [1501/3125], Training Loss: 0.5899612903594971\n",
      "Epoch: [3/6], Step: [1601/3125], Validation Acc: 63.4\n",
      "Epoch: [3/6], Step: [1601/3125], Training Loss: 0.881278932094574\n",
      "Epoch: [3/6], Step: [1701/3125], Validation Acc: 63.6\n",
      "Epoch: [3/6], Step: [1701/3125], Training Loss: 0.6777219176292419\n",
      "Epoch: [3/6], Step: [1801/3125], Validation Acc: 64.0\n",
      "Epoch: [3/6], Step: [1801/3125], Training Loss: 1.0157697200775146\n",
      "Epoch: [3/6], Step: [1901/3125], Validation Acc: 62.1\n",
      "Epoch: [3/6], Step: [1901/3125], Training Loss: 0.9346681237220764\n",
      "Epoch: [3/6], Step: [2001/3125], Validation Acc: 64.5\n",
      "Epoch: [3/6], Step: [2001/3125], Training Loss: 0.7672458291053772\n",
      "Epoch: [3/6], Step: [2101/3125], Validation Acc: 64.4\n",
      "Epoch: [3/6], Step: [2101/3125], Training Loss: 0.7567455172538757\n",
      "Epoch: [3/6], Step: [2201/3125], Validation Acc: 64.3\n",
      "Epoch: [3/6], Step: [2201/3125], Training Loss: 0.5839978456497192\n",
      "Epoch: [3/6], Step: [2301/3125], Validation Acc: 64.0\n",
      "Epoch: [3/6], Step: [2301/3125], Training Loss: 0.8140623569488525\n",
      "Epoch: [3/6], Step: [2401/3125], Validation Acc: 64.5\n",
      "Epoch: [3/6], Step: [2401/3125], Training Loss: 0.9127020239830017\n",
      "Epoch: [3/6], Step: [2501/3125], Validation Acc: 63.5\n",
      "Epoch: [3/6], Step: [2501/3125], Training Loss: 0.6499820351600647\n",
      "Epoch: [3/6], Step: [2601/3125], Validation Acc: 63.6\n",
      "Epoch: [3/6], Step: [2601/3125], Training Loss: 0.960496723651886\n",
      "Epoch: [3/6], Step: [2701/3125], Validation Acc: 65.6\n",
      "Epoch: [3/6], Step: [2701/3125], Training Loss: 0.8699118494987488\n",
      "Epoch: [3/6], Step: [2801/3125], Validation Acc: 66.0\n",
      "Epoch: [3/6], Step: [2801/3125], Training Loss: 0.5675413012504578\n",
      "Epoch: [3/6], Step: [2901/3125], Validation Acc: 63.1\n",
      "Epoch: [3/6], Step: [2901/3125], Training Loss: 1.0853599309921265\n",
      "Epoch: [3/6], Step: [3001/3125], Validation Acc: 62.9\n",
      "Epoch: [3/6], Step: [3001/3125], Training Loss: 0.7202630043029785\n",
      "Epoch: [3/6], Step: [3101/3125], Validation Acc: 65.3\n",
      "Epoch: [3/6], Step: [3101/3125], Training Loss: 0.845272421836853\n",
      "Epoch: [4/6], Step: [101/3125], Validation Acc: 64.1\n",
      "Epoch: [4/6], Step: [101/3125], Training Loss: 0.792428731918335\n",
      "Epoch: [4/6], Step: [201/3125], Validation Acc: 66.1\n",
      "Epoch: [4/6], Step: [201/3125], Training Loss: 0.4746566712856293\n",
      "Epoch: [4/6], Step: [301/3125], Validation Acc: 64.9\n",
      "Epoch: [4/6], Step: [301/3125], Training Loss: 0.6823534369468689\n",
      "Epoch: [4/6], Step: [401/3125], Validation Acc: 65.5\n",
      "Epoch: [4/6], Step: [401/3125], Training Loss: 0.6629869341850281\n",
      "Epoch: [4/6], Step: [501/3125], Validation Acc: 66.9\n",
      "Epoch: [4/6], Step: [501/3125], Training Loss: 0.6634739637374878\n",
      "Epoch: [4/6], Step: [601/3125], Validation Acc: 66.3\n",
      "Epoch: [4/6], Step: [601/3125], Training Loss: 0.7930692434310913\n",
      "Epoch: [4/6], Step: [701/3125], Validation Acc: 64.9\n",
      "Epoch: [4/6], Step: [701/3125], Training Loss: 0.8510207533836365\n",
      "Epoch: [4/6], Step: [801/3125], Validation Acc: 66.3\n",
      "Epoch: [4/6], Step: [801/3125], Training Loss: 0.7188906669616699\n",
      "Epoch: [4/6], Step: [901/3125], Validation Acc: 64.1\n",
      "Epoch: [4/6], Step: [901/3125], Training Loss: 0.7412323355674744\n",
      "Epoch: [4/6], Step: [1001/3125], Validation Acc: 64.4\n",
      "Epoch: [4/6], Step: [1001/3125], Training Loss: 0.6210086345672607\n",
      "Epoch: [4/6], Step: [1101/3125], Validation Acc: 65.2\n",
      "Epoch: [4/6], Step: [1101/3125], Training Loss: 0.7032861113548279\n",
      "Epoch: [4/6], Step: [1201/3125], Validation Acc: 65.0\n",
      "Epoch: [4/6], Step: [1201/3125], Training Loss: 0.6389349102973938\n",
      "Epoch: [4/6], Step: [1301/3125], Validation Acc: 66.9\n",
      "Epoch: [4/6], Step: [1301/3125], Training Loss: 0.5496084094047546\n",
      "Epoch: [4/6], Step: [1401/3125], Validation Acc: 65.8\n",
      "Epoch: [4/6], Step: [1401/3125], Training Loss: 0.6522670984268188\n",
      "Epoch: [4/6], Step: [1501/3125], Validation Acc: 66.5\n",
      "Epoch: [4/6], Step: [1501/3125], Training Loss: 0.6227022409439087\n",
      "Epoch: [4/6], Step: [1601/3125], Validation Acc: 65.9\n",
      "Epoch: [4/6], Step: [1601/3125], Training Loss: 0.7540130615234375\n",
      "Epoch: [4/6], Step: [1701/3125], Validation Acc: 64.9\n",
      "Epoch: [4/6], Step: [1701/3125], Training Loss: 0.7254266738891602\n",
      "Epoch: [4/6], Step: [1801/3125], Validation Acc: 65.8\n",
      "Epoch: [4/6], Step: [1801/3125], Training Loss: 0.9874469041824341\n",
      "Epoch: [4/6], Step: [1901/3125], Validation Acc: 65.1\n",
      "Epoch: [4/6], Step: [1901/3125], Training Loss: 0.9096752405166626\n",
      "Epoch: [4/6], Step: [2001/3125], Validation Acc: 66.8\n",
      "Epoch: [4/6], Step: [2001/3125], Training Loss: 0.7373602390289307\n",
      "Epoch: [4/6], Step: [2101/3125], Validation Acc: 67.5\n",
      "Epoch: [4/6], Step: [2101/3125], Training Loss: 0.7129511833190918\n",
      "Epoch: [4/6], Step: [2201/3125], Validation Acc: 66.4\n",
      "Epoch: [4/6], Step: [2201/3125], Training Loss: 0.5641710758209229\n",
      "Epoch: [4/6], Step: [2301/3125], Validation Acc: 65.5\n",
      "Epoch: [4/6], Step: [2301/3125], Training Loss: 0.7064201831817627\n",
      "Epoch: [4/6], Step: [2401/3125], Validation Acc: 66.9\n",
      "Epoch: [4/6], Step: [2401/3125], Training Loss: 0.8728216290473938\n",
      "Epoch: [4/6], Step: [2501/3125], Validation Acc: 65.5\n",
      "Epoch: [4/6], Step: [2501/3125], Training Loss: 0.6099876165390015\n",
      "Epoch: [4/6], Step: [2601/3125], Validation Acc: 67.5\n",
      "Epoch: [4/6], Step: [2601/3125], Training Loss: 0.8578015565872192\n",
      "Epoch: [4/6], Step: [2701/3125], Validation Acc: 67.4\n",
      "Epoch: [4/6], Step: [2701/3125], Training Loss: 0.857029378414154\n",
      "Epoch: [4/6], Step: [2801/3125], Validation Acc: 68.5\n",
      "Epoch: [4/6], Step: [2801/3125], Training Loss: 0.5668726563453674\n",
      "Epoch: [4/6], Step: [2901/3125], Validation Acc: 68.5\n",
      "Epoch: [4/6], Step: [2901/3125], Training Loss: 0.9781451225280762\n",
      "Epoch: [4/6], Step: [3001/3125], Validation Acc: 67.7\n",
      "Epoch: [4/6], Step: [3001/3125], Training Loss: 0.7181555032730103\n",
      "Epoch: [4/6], Step: [3101/3125], Validation Acc: 69.5\n",
      "Epoch: [4/6], Step: [3101/3125], Training Loss: 0.7990812659263611\n",
      "Epoch: [5/6], Step: [101/3125], Validation Acc: 67.0\n",
      "Epoch: [5/6], Step: [101/3125], Training Loss: 0.7781923413276672\n",
      "Epoch: [5/6], Step: [201/3125], Validation Acc: 65.6\n",
      "Epoch: [5/6], Step: [201/3125], Training Loss: 0.5206196308135986\n",
      "Epoch: [5/6], Step: [301/3125], Validation Acc: 66.8\n",
      "Epoch: [5/6], Step: [301/3125], Training Loss: 0.6759400963783264\n",
      "Epoch: [5/6], Step: [401/3125], Validation Acc: 68.0\n",
      "Epoch: [5/6], Step: [401/3125], Training Loss: 0.6353051662445068\n",
      "Epoch: [5/6], Step: [501/3125], Validation Acc: 67.8\n",
      "Epoch: [5/6], Step: [501/3125], Training Loss: 0.631273090839386\n",
      "Epoch: [5/6], Step: [601/3125], Validation Acc: 66.5\n",
      "Epoch: [5/6], Step: [601/3125], Training Loss: 0.6190431118011475\n",
      "Epoch: [5/6], Step: [701/3125], Validation Acc: 66.7\n",
      "Epoch: [5/6], Step: [701/3125], Training Loss: 0.8048279881477356\n",
      "Epoch: [5/6], Step: [801/3125], Validation Acc: 66.4\n",
      "Epoch: [5/6], Step: [801/3125], Training Loss: 0.717268168926239\n",
      "Epoch: [5/6], Step: [901/3125], Validation Acc: 65.8\n",
      "Epoch: [5/6], Step: [901/3125], Training Loss: 0.6799238324165344\n",
      "Epoch: [5/6], Step: [1001/3125], Validation Acc: 67.5\n",
      "Epoch: [5/6], Step: [1001/3125], Training Loss: 0.5714613199234009\n",
      "Epoch: [5/6], Step: [1101/3125], Validation Acc: 66.4\n",
      "Epoch: [5/6], Step: [1101/3125], Training Loss: 0.6201595067977905\n",
      "Epoch: [5/6], Step: [1201/3125], Validation Acc: 67.3\n",
      "Epoch: [5/6], Step: [1201/3125], Training Loss: 0.6097691059112549\n",
      "Epoch: [5/6], Step: [1301/3125], Validation Acc: 67.1\n",
      "Epoch: [5/6], Step: [1301/3125], Training Loss: 0.4698384702205658\n",
      "Epoch: [5/6], Step: [1401/3125], Validation Acc: 67.8\n",
      "Epoch: [5/6], Step: [1401/3125], Training Loss: 0.6366499066352844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/6], Step: [1501/3125], Validation Acc: 67.1\n",
      "Epoch: [5/6], Step: [1501/3125], Training Loss: 0.6125738620758057\n",
      "Epoch: [5/6], Step: [1601/3125], Validation Acc: 67.7\n",
      "Epoch: [5/6], Step: [1601/3125], Training Loss: 0.6935473680496216\n",
      "Epoch: [5/6], Step: [1701/3125], Validation Acc: 65.2\n",
      "Epoch: [5/6], Step: [1701/3125], Training Loss: 0.702570915222168\n",
      "Epoch: [5/6], Step: [1801/3125], Validation Acc: 67.6\n",
      "Epoch: [5/6], Step: [1801/3125], Training Loss: 0.9580276012420654\n",
      "Epoch: [5/6], Step: [1901/3125], Validation Acc: 66.8\n",
      "Epoch: [5/6], Step: [1901/3125], Training Loss: 0.9739399552345276\n",
      "Epoch: [5/6], Step: [2001/3125], Validation Acc: 67.0\n",
      "Epoch: [5/6], Step: [2001/3125], Training Loss: 0.7424696087837219\n",
      "Epoch: [5/6], Step: [2101/3125], Validation Acc: 68.2\n",
      "Epoch: [5/6], Step: [2101/3125], Training Loss: 0.6338272094726562\n",
      "Epoch: [5/6], Step: [2201/3125], Validation Acc: 67.7\n",
      "Epoch: [5/6], Step: [2201/3125], Training Loss: 0.5360807180404663\n",
      "Epoch: [5/6], Step: [2301/3125], Validation Acc: 66.5\n",
      "Epoch: [5/6], Step: [2301/3125], Training Loss: 0.6326903104782104\n",
      "Epoch: [5/6], Step: [2401/3125], Validation Acc: 66.7\n",
      "Epoch: [5/6], Step: [2401/3125], Training Loss: 0.8267500400543213\n",
      "Epoch: [5/6], Step: [2501/3125], Validation Acc: 68.1\n",
      "Epoch: [5/6], Step: [2501/3125], Training Loss: 0.5768746137619019\n",
      "Epoch: [5/6], Step: [2601/3125], Validation Acc: 69.3\n",
      "Epoch: [5/6], Step: [2601/3125], Training Loss: 0.7928487062454224\n",
      "Epoch: [5/6], Step: [2701/3125], Validation Acc: 67.3\n",
      "Epoch: [5/6], Step: [2701/3125], Training Loss: 0.7851987481117249\n",
      "Epoch: [5/6], Step: [2801/3125], Validation Acc: 69.1\n",
      "Epoch: [5/6], Step: [2801/3125], Training Loss: 0.5027385950088501\n",
      "Epoch: [5/6], Step: [2901/3125], Validation Acc: 68.0\n",
      "Epoch: [5/6], Step: [2901/3125], Training Loss: 0.9983008503913879\n",
      "Epoch: [5/6], Step: [3001/3125], Validation Acc: 69.1\n",
      "Epoch: [5/6], Step: [3001/3125], Training Loss: 0.6386316418647766\n",
      "Epoch: [5/6], Step: [3101/3125], Validation Acc: 68.6\n",
      "Epoch: [5/6], Step: [3101/3125], Training Loss: 0.7644928097724915\n",
      "Epoch: [6/6], Step: [101/3125], Validation Acc: 68.2\n",
      "Epoch: [6/6], Step: [101/3125], Training Loss: 0.707488477230072\n",
      "Epoch: [6/6], Step: [201/3125], Validation Acc: 67.2\n",
      "Epoch: [6/6], Step: [201/3125], Training Loss: 0.5085332989692688\n",
      "Epoch: [6/6], Step: [301/3125], Validation Acc: 67.5\n",
      "Epoch: [6/6], Step: [301/3125], Training Loss: 0.6343637108802795\n",
      "Epoch: [6/6], Step: [401/3125], Validation Acc: 68.2\n",
      "Epoch: [6/6], Step: [401/3125], Training Loss: 0.5852365493774414\n",
      "Epoch: [6/6], Step: [501/3125], Validation Acc: 68.5\n",
      "Epoch: [6/6], Step: [501/3125], Training Loss: 0.5834022760391235\n",
      "Epoch: [6/6], Step: [601/3125], Validation Acc: 66.5\n",
      "Epoch: [6/6], Step: [601/3125], Training Loss: 0.5248000025749207\n",
      "Epoch: [6/6], Step: [701/3125], Validation Acc: 67.5\n",
      "Epoch: [6/6], Step: [701/3125], Training Loss: 0.8228977918624878\n",
      "Epoch: [6/6], Step: [801/3125], Validation Acc: 67.5\n",
      "Epoch: [6/6], Step: [801/3125], Training Loss: 0.5803003907203674\n",
      "Epoch: [6/6], Step: [901/3125], Validation Acc: 66.5\n",
      "Epoch: [6/6], Step: [901/3125], Training Loss: 0.6263678073883057\n",
      "Epoch: [6/6], Step: [1001/3125], Validation Acc: 67.2\n",
      "Epoch: [6/6], Step: [1001/3125], Training Loss: 0.5120808482170105\n",
      "Epoch: [6/6], Step: [1101/3125], Validation Acc: 66.9\n",
      "Epoch: [6/6], Step: [1101/3125], Training Loss: 0.5789186358451843\n",
      "Epoch: [6/6], Step: [1201/3125], Validation Acc: 67.9\n",
      "Epoch: [6/6], Step: [1201/3125], Training Loss: 0.6259902119636536\n",
      "Epoch: [6/6], Step: [1301/3125], Validation Acc: 68.2\n",
      "Epoch: [6/6], Step: [1301/3125], Training Loss: 0.477788507938385\n",
      "Epoch: [6/6], Step: [1401/3125], Validation Acc: 67.8\n",
      "Epoch: [6/6], Step: [1401/3125], Training Loss: 0.6133542060852051\n",
      "Epoch: [6/6], Step: [1501/3125], Validation Acc: 68.1\n",
      "Epoch: [6/6], Step: [1501/3125], Training Loss: 0.5860344171524048\n",
      "Epoch: [6/6], Step: [1601/3125], Validation Acc: 68.5\n",
      "Epoch: [6/6], Step: [1601/3125], Training Loss: 0.6340996026992798\n",
      "Epoch: [6/6], Step: [1701/3125], Validation Acc: 67.4\n",
      "Epoch: [6/6], Step: [1701/3125], Training Loss: 0.644214928150177\n",
      "Epoch: [6/6], Step: [1801/3125], Validation Acc: 68.5\n",
      "Epoch: [6/6], Step: [1801/3125], Training Loss: 0.9066606760025024\n",
      "Epoch: [6/6], Step: [1901/3125], Validation Acc: 67.0\n",
      "Epoch: [6/6], Step: [1901/3125], Training Loss: 0.9335876107215881\n",
      "Epoch: [6/6], Step: [2001/3125], Validation Acc: 67.2\n",
      "Epoch: [6/6], Step: [2001/3125], Training Loss: 0.6833512187004089\n",
      "Epoch: [6/6], Step: [2101/3125], Validation Acc: 67.6\n",
      "Epoch: [6/6], Step: [2101/3125], Training Loss: 0.5243755578994751\n",
      "Epoch: [6/6], Step: [2201/3125], Validation Acc: 67.1\n",
      "Epoch: [6/6], Step: [2201/3125], Training Loss: 0.5804002285003662\n",
      "Epoch: [6/6], Step: [2301/3125], Validation Acc: 67.3\n",
      "Epoch: [6/6], Step: [2301/3125], Training Loss: 0.5710239410400391\n",
      "Epoch: [6/6], Step: [2401/3125], Validation Acc: 68.5\n",
      "Epoch: [6/6], Step: [2401/3125], Training Loss: 0.7929279208183289\n",
      "Epoch: [6/6], Step: [2501/3125], Validation Acc: 68.9\n",
      "Epoch: [6/6], Step: [2501/3125], Training Loss: 0.5344056487083435\n",
      "Epoch: [6/6], Step: [2601/3125], Validation Acc: 68.3\n",
      "Epoch: [6/6], Step: [2601/3125], Training Loss: 0.7195602655410767\n",
      "Epoch: [6/6], Step: [2701/3125], Validation Acc: 69.5\n",
      "Epoch: [6/6], Step: [2701/3125], Training Loss: 0.7812697887420654\n",
      "Epoch: [6/6], Step: [2801/3125], Validation Acc: 69.0\n",
      "Epoch: [6/6], Step: [2801/3125], Training Loss: 0.4167693257331848\n",
      "Epoch: [6/6], Step: [2901/3125], Validation Acc: 68.1\n",
      "Epoch: [6/6], Step: [2901/3125], Training Loss: 1.0590282678604126\n",
      "Epoch: [6/6], Step: [3001/3125], Validation Acc: 69.7\n",
      "Epoch: [6/6], Step: [3001/3125], Training Loss: 0.4896969497203827\n",
      "Epoch: [6/6], Step: [3101/3125], Validation Acc: 69.0\n",
      "Epoch: [6/6], Step: [3101/3125], Training Loss: 0.7466114163398743\n",
      "Max Validation Accuracy: 69.7\n"
     ]
    }
   ],
   "source": [
    "model = TwoSentenceModel(emb_size = 300, hidden_size=300, num_layers=1, num_classes=3).to(device)\n",
    "max_val_acc, losses, xs, val_accs = train_model(model, num_epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f831e210e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_trainable_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "plot_loss_and_validation_curves(losses, xs, val_accs, \"GRU - Standard, Element-wise multiply, # params: {}\".format(get_trainable_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"/home/vrajiv/rnn-cnn-natural-language-inference/best_rnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val = pd.read_csv('mnli_val.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th percentile for sentence length (in characters): 151.0\n"
     ]
    }
   ],
   "source": [
    "sentence_length_75 = pd.Series([len(x) for x in mnli_val['sentence1']]).describe()['75%']\n",
    "print(\"75th percentile for sentence length (in characters): {}\".format(sentence_length_75))\n",
    "MAX_SENTENCE_LENGTH = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build dictionary of (sent1, sent2, label) data, by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val_dict = {}\n",
    "for x in mnli_val['genre'].unique():\n",
    "    filtered = mnli_val[mnli_val['genre'] == x]\n",
    "    mnli_val_dict[x] = {}\n",
    "    mnli_val_dict[x][\"sent1s\"] = list(filtered[\"sentence1\"])\n",
    "    mnli_val_dict[x][\"sent2s\"] = list(filtered[\"sentence2\"])\n",
    "    mnli_val_dict[x][\"label\"] = convert_labels_to_integers(list(filtered[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n",
      "[0 1 2]\n",
      "1005\n",
      "[0 1 2]\n",
      "1002\n",
      "[0 1 2]\n",
      "1016\n",
      "[0 1 2]\n",
      "982\n",
      "[0 1 2]\n",
      "Now open political debate flourished , especially in Calcutta where Karl Marx was much appreciated .\n",
      "Now political debate died down in Calcutta especially , where Karl Marx was hated .\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for x in mnli_val_dict.keys():\n",
    "    print(len(mnli_val_dict[x][\"sent1s\"]))\n",
    "    print(np.unique(mnli_val_dict[x][\"label\"]))\n",
    "    \n",
    "# quick verify\n",
    "verify_order(mnli_val_dict['travel'][\"sent1s\"], mnli_val_dict['travel'][\"sent2s\"], mnli_val_dict['travel'][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed for shuffling: 95\n",
      "\n",
      "Verifying that the data and label match after shuffling\n",
      "'You burned down my house . '\n",
      "'You used matches and gasoline to commit arson . '\n",
      "2\n",
      "I sha n't stop you . ''\n",
      "You can stop .\n",
      "0\n",
      "\n",
      "Tokenizing sentence 1 list...\n",
      "done!\n",
      "\n",
      "Tokenizing sentence 2 list... \n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 1 list...\n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 2 list...\n",
      "done!\n",
      "Random seed for shuffling: 79\n",
      "\n",
      "Verifying that the data and label match after shuffling\n",
      "maybe adult literacy maybe you know composition writing maybe you know uh volunteering you know on a tutor line or though the even through the elementary schools for help with homework or the other part of me says is God i 've had enough kids do i really\n",
      "maybe I could volunteer to help coach sports since I 've helped all my children be successful in sports\n",
      "0\n",
      "that 's right you can work yourself to death well i 'm sorry to hear your color did n't come out so good over the weekend\n",
      "I 'm sorry it did n't turn out as planned .\n",
      "1\n",
      "\n",
      "Tokenizing sentence 1 list...\n",
      "done!\n",
      "\n",
      "Tokenizing sentence 2 list... \n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 1 list...\n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 2 list...\n",
      "done!\n",
      "Random seed for shuffling: 51\n",
      "\n",
      "Verifying that the data and label match after shuffling\n",
      "He 's too cautious .\n",
      "He is cautious due to a lack of confidence .\n",
      "2\n",
      "Acquaintances of mine have become Orthodox because of the codes .\n",
      "My acquaintances shied away from becoming Orthodox because of the codes .\n",
      "0\n",
      "\n",
      "Tokenizing sentence 1 list...\n",
      "done!\n",
      "\n",
      "Tokenizing sentence 2 list... \n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 1 list...\n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 2 list...\n",
      "done!\n",
      "Random seed for shuffling: 63\n",
      "\n",
      "Verifying that the data and label match after shuffling\n",
      "Among runners-up is Boston solo Eleanor Newhoff .\n",
      "Boston solo Eleanor Newhoff won .\n",
      "0\n",
      "Congress ' determination to make agencies accountable for their performance lay at the heart of two landmark reforms of the 1990 the Chief Financial Officers ( CFO ) Act of 1990 and the Government Performance and Results Act of 1993 ( GPRA ) .\n",
      "Congress made several big reforms in the nineties to ensure agencies are held accountable for their actions .\n",
      "1\n",
      "\n",
      "Tokenizing sentence 1 list...\n",
      "done!\n",
      "\n",
      "Tokenizing sentence 2 list... \n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 1 list...\n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 2 list...\n",
      "done!\n",
      "Random seed for shuffling: 72\n",
      "\n",
      "Verifying that the data and label match after shuffling\n",
      "De Wit worked from likenesses of actual monarchs to produce his portraits .\n",
      "To create his portraits , De Wit used the likenesses of real monarchs .\n",
      "1\n",
      "The rock has a soft texture and can be bought in a variety of shapes .\n",
      "The rock is harder than most types of rock .\n",
      "0\n",
      "\n",
      "Tokenizing sentence 1 list...\n",
      "done!\n",
      "\n",
      "Tokenizing sentence 2 list... \n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 1 list...\n",
      "done!\n",
      "\n",
      "One-hot encoding words for sentence 2 list...\n",
      "done!\n",
      "Genre fiction has validation accuracy: 45.527638190954775\n",
      "Genre telephone has validation accuracy: 40.398009950248756\n",
      "Genre slate has validation accuracy: 40.5189620758483\n",
      "Genre government has validation accuracy: 41.43700787401575\n",
      "Genre travel has validation accuracy: 41.64969450101833\n"
     ]
    }
   ],
   "source": [
    "# for each genre, build validation set and evaluate on it. \n",
    "cnn_results = {}\n",
    "model = TwoSentenceModel(emb_size = 300, hidden_size=300, num_layers=1, num_classes=3).to(device)\n",
    "model.load_state_dict(torch.load(\"/home/vrajiv/rnn-cnn-natural-language-inference/best_rnn\"))\n",
    "model.eval()\n",
    "for genre in mnli_val_dict.keys():\n",
    "    sent1_val_indices, sent2_val_indices, val_label = data_pipeline(mnli_val_dict[genre][\"sent1s\"], \n",
    "                                                                    mnli_val_dict[genre][\"sent2s\"], \n",
    "                                                                    mnli_val_dict[genre][\"label\"])\n",
    "    val_dataset = TwoSentencesDataset(sent1_val_indices, sent2_val_indices, val_label)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                             batch_size=BATCH_SIZE, \n",
    "                                             collate_fn=twosentences_collate_func,\n",
    "                                             #shuffle=True\n",
    "                                             )\n",
    "    cnn_results[genre] = test_model(val_loader, model)\n",
    "\n",
    "for genre in mnli_val_dict.keys():\n",
    "    print(\"Genre {} has validation accuracy: {}\".format(genre, cnn_results[genre]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 correct and 3 incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  1\n",
      "correct:  0\n",
      "incorrect:  1\n",
      "incorrect:  0\n",
      "correct:  2\n",
      "incorrect:  2\n"
     ]
    }
   ],
   "source": [
    "model = TwoSentenceModel(emb_size = 300, hidden_size=300, num_layers=1, num_classes=3).to(device)\n",
    "model.load_state_dict(torch.load(\"/home/vrajiv/rnn-cnn-natural-language-inference/best_rnn\"))\n",
    "model.eval()\n",
    "\n",
    "eval_dataset = TwoSentencesDataset(sent1_val_indices, sent2_val_indices, val_label)\n",
    "eval_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=1, \n",
    "                                           collate_fn=twosentences_collate_func,\n",
    "                                           #shuffle=True\n",
    "                                          )\n",
    "\n",
    "i = 0\n",
    "incorrect_data = []\n",
    "correct_data = []\n",
    "corr_count = 0\n",
    "incorr_count = 0\n",
    "for data, sent1_lengths, sent2_lengths, labels in eval_loader:\n",
    "        data_batch, sent1_length_batch, sent2_length_batch, label_batch = data.to(device), sent1_lengths.to(device), sent2_lengths.to(device), labels.to(device)\n",
    "        outputs = F.softmax(model(data_batch, sent1_length_batch, sent2_length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        if (predicted.squeeze().item() == labels.squeeze().item() and corr_count <= 2):\n",
    "            corr_count += 1\n",
    "            correct_data.append(snli_val.iloc[[i]])\n",
    "            print(\"correct: \", labels.squeeze().item())\n",
    "        elif (predicted.squeeze().item() != labels.squeeze().item() and incorr_count <= 2):\n",
    "            incorr_count += 1\n",
    "            incorrect_data.append(snli_val.iloc[[i]])\n",
    "            print(\"incorrect: \", labels.squeeze().item())\n",
    "        i += 1\n",
    "        \n",
    "        if corr_count == 3 and incorr_count == 3:\n",
    "            break       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Three women on a stage , one wearing red shoes...\n",
      "Name: sentence1, dtype: object\n",
      "0    There are two women standing on the stage\n",
      "Name: sentence2, dtype: object\n",
      "0    contradiction\n",
      "Name: label, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "1    Four people sit on a subway two read books , o...\n",
      "Name: sentence1, dtype: object\n",
      "1    Multiple people are on a subway together , wit...\n",
      "Name: sentence2, dtype: object\n",
      "1    entailment\n",
      "Name: label, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "4    Man observes a wavelength given off by an elec...\n",
      "Name: sentence1, dtype: object\n",
      "4    The man is examining what wavelength is given ...\n",
      "Name: sentence2, dtype: object\n",
      "4    entailment\n",
      "Name: label, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(correct_data)):\n",
    "    print(correct_data[i][\"sentence1\"])\n",
    "    print(correct_data[i][\"sentence2\"])\n",
    "    print(correct_data[i][\"label\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    bicycles stationed while a group of people soc...\n",
      "Name: sentence1, dtype: object\n",
      "2    People get together near a stand of bicycles .\n",
      "Name: sentence2, dtype: object\n",
      "2    entailment\n",
      "Name: label, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "3    Man in overalls with two horses .\n",
      "Name: sentence1, dtype: object\n",
      "3    a man in overalls with two horses\n",
      "Name: sentence2, dtype: object\n",
      "3    entailment\n",
      "Name: label, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "6    Two men are listening to music through headpho...\n",
      "Name: sentence1, dtype: object\n",
      "6    Two men listen to music .\n",
      "Name: sentence2, dtype: object\n",
      "6    entailment\n",
      "Name: label, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(incorrect_data)):\n",
    "    print(incorrect_data[i][\"sentence1\"])\n",
    "    print(incorrect_data[i][\"sentence2\"])\n",
    "    print(incorrect_data[i][\"label\"])\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the three correct predictions, it seems like the RNN model can find contradictions by comparing the number of objects (three women vs two women, four people vs multiple people), as well as sentences with multiple coexisting words (wavelength, given, man) and similar grammatical structures. \n",
    "\n",
    "For the three incorrect predictions, it seems to have trouble with different forms of verbs (\"listen\" vs \"are listening\"), and different grammatical structures (\"people get together\" vs \"...while a group of people\"). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
